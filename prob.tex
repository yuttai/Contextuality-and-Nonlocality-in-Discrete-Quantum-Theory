\documentclass{article}
\usepackage{fullpage}
\usepackage{bbm}
\usepackage{bbold}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{array}
\usepackage{mathrsfs}
\usepackage[all]{xy}

\theoremstyle{remark}
\newtheorem{example}{Example}
\newcommand{\events}{\ensuremath{\mathcal{E}}}
\newcommand{\qevents}{\ensuremath{\mathcal{E}}}
\newcommand{\pmeas}{\ensuremath{\mu}}
\newcommand{\Hilb}{\mathcal{H}}
\newcommand{\pr}[2]{\langle #1, #2 \rangle}
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\ip}[2]{\langle #1 | #2 \rangle}
\newcommand{\proj}[1]{|#1 \rangle\langle #1 |}
\newcommand{\ps}{\texttt{+}}
\newcommand{\ms}{\texttt{-}}

\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\newcommand{\yutsung}[1]{\fbox{\begin{minipage}{0.9\textwidth}\color{purple}{Yu-Tsung says: #1}\end{minipage}}}
\newcommand{\amr}[1]{\fbox{\begin{minipage}{0.9\textwidth}\color{green}{Amr says: #1}\end{minipage}}}
\newcommand{\ffzd}[1]{{\mathbb{F}^{d\;*}_{#1}}}
\def\C{{\mathbb{C}}}
\newcommand{\ff}[1]{\mathbb{F}_{#1}}

\begin{document}
\title{Probability}
\author{}
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Probability Spaces} 

%%%%%
\subsection{Classical Probability Spaces}
 
Probability
theory~\cite{inun.425605319950101,GrahamKnuthPatashnik1994,rohatgi2011introduction}
is defined using the notions of a \emph{sample space} $\Omega$, a
space of \emph{events}~$\events$, and a \emph{probability
  measure}~$\pmeas$. In this paper, we will only consider
\emph{finite} sample spaces: we therefore define a sample space
$\Omega$ as an arbitrary non-empty finite set, the space of events
$\events$ as $2^\Omega$, the powerset of $\Omega$, and the \emph{probability
measure} as a function $\pmeas : \events \rightarrow [0,1]$ such that:
\begin{itemize}
\item $\pmeas(\Omega) = 1$, and 
\item for a collection of pairwise disjoint events $E_i$, the probability
measures are additive $\pmeas(\bigcup E_i) = \sum \pmeas(E_i)$. 
\end{itemize}

\emph{Example of a problem on a finite sample space} (Two coin experiment)
Consider an experiment that tosses two coins. We have four possible outcomes that constitute the
  sample space $\Omega = \{ HH, HT, TH, TT \}$. The event that the
  first coin is ``heads'' is $\{ HH, HT \}$; the event that the two
  coins land on opposite sides is $\{ HT, TH \}$; the event that at
  least one coin is tails is $\{ HT, TH, TT\}$. Depending on the
  assumptions regarding the coins, we can define several probability
  measures. Here is a possible one:
\[\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\pmeas(\emptyset) &=& 0 \\
\pmeas(\{ HH \}) &=& 1/3 \\
\pmeas(\{ HT \}) &=& 0 \\
\pmeas(\{ TH \}) &=& 2/3 \\
\pmeas(\{ TT \}) &=& 0 \\
\pmeas(\{  HH, HT \}) &=& 1/3 \\
\pmeas(\{  HH, TH \}) &=& 1 \\
\pmeas(\{  HH , TT \}) &=& 1/3 
\end{array} & \begin{array}{rcl}
\pmeas(\{  HT, TH \}) &=& 2/3 \\
\pmeas(\{  HT , TT \}) &=& 0 \\
\pmeas(\{  TH , TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH \}) &=& 1 \\
\pmeas(\{  HH, HT, TT \}) &=& 1/3 \\
\pmeas(\{  HH, TH, TT \}) &=& 1 \\
\pmeas(\{  HT, TH, TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH, TT \}) &=& 1
\end{array}
\end{array}\]
Note that the probability measure for disjoint events such as $\{ HT \}$ and
$\{ TH \}$ do indeed add.

%%%%%
\subsection{Quantum Probability Spaces}

The mathematical framework above assumes that one has complete
knowledge of the events and their relationships. But even in many
classical situations, the structure of the event space is only
partially known and the precise dependence of two events on each other
cannot be determined with certainty. In the quantum case, this partial
knowledge is compounded by the fact that not all quantum events can be
observed simultaneously.  Indeed, in the quantum world, there are
non-commuting events which cannot even happen simultaneously. To
accommodate these more complex situations, we abandon the
sample space~$\Omega$ and define and reason directly about
events. A quantum probability space consist of just two
components: a set of events $\qevents$ and a probability measure
$\mu : \qevents \rightarrow [0,1]$. We give an example before giving
the formal definition.

Consider the two-qubit Hilbert space with computational basis
$\ket{0}$ and $\ket{1}$ and states:
\[
\ket{\ps}=\frac{\ket{0}+\ket{1}}{\sqrt{2}}, \qquad\ket{\ms}=\frac{\ket{0}-\ket{1}}{\sqrt{2}}\,.
\]
The set of events associated with this Hilbert space consists of all
projections including the empty projection $\mathbb{0}$ and the unit
projection $\mathbb{1} = \proj{0}+\proj{1}$:
\[ 
\{ \mathbb{0}, \proj{0}, \proj{1}, \proj{\ps}, \proj{\ms}, \ldots, \mathbb{1}\}
\]
Each event is interpreted as a possible post post-measurement state of
a quantum system as follows: given some arbitrary current quantum state
$\ket{\psi}$ to be measured, the event $\proj{0}$ states that the
post-measurement state will be $\ket{0}$; the event $\proj{1}$ states
that the post-measurement state will be $\ket{1}$; the event
$\proj{\ps}$ states that the post-measurement state will be
$\ket{\ps}$; the event $\proj{\ms}$ states that the post-measurement
state will be $\ket{\ms}$; the event $\mathbb{1}$ states that the
post-measurement state will be a linear combination of $\ket{0}$ and
$\ket{1}$; and the event $\mathbb{0}$ states that the post-measurement
state will be the empty state.

Irrespective of the current state $\ket{\psi}$ and
irrespective of the particular experiment, the probability of event
$\mathbb{0}$ will always be 0 (it is an impossible event) and the
probability of event $\mathbb{1}$ will always be 1 (it is a certain
event). The probabilities attached to other events will depend on the
particular state in question. If the state is $\ket{0}$, the
probability of event $\proj{0}$ is 1; the probability of event
$\proj{1}$ is 0; the probability of event $\proj{\ps}$ is
$\frac{1}{2}$; and the probability of event $\proj{\ms}$ is
$\frac{1}{2}$. If the state is $\ket{\ps}$, the probability of each
event $\proj{0}$ and $\proj{1}$ will be $\frac{1}{2}$; the
probability of event $\proj{\ps}$ is 1; and the probability of event
$\proj{\ms}$ is 0. 

% \begin{itemize}
% \item Family I: $\proj{0}$, $\proj{1}$ 
% \item Family II: $\proj{\ps}$, $\proj{\ms}$
% \end{itemize}
% In family I, all operators can be expressed as $\left\{ \lambda_{1}\proj{0}+\lambda_{2}\proj{1}~\middle|~\lambda_{1},\lambda_{2}\in\mathbb{C}\right\} $.
% In order to identify projectors among them, we need to solve the following
% two equations.
% \begin{eqnarray*}
% \lambda_{1}\proj{0}+\lambda_{2}\proj{1} & = & \left(\lambda_{1}\proj{0}+\lambda_{2}\proj{1}\right)^{*}=\lambda_{1}^{*}\proj{0}+\lambda_{2}^{*}\proj{1}\\
% \lambda_{1}\proj{0}+\lambda_{2}\proj{1} & = & \left(\lambda_{1}\proj{0}+\lambda_{2}\proj{1}\right)^{2}=\lambda_{1}^{2}\proj{0}+\lambda_{2}^{2}\proj{1}
% \end{eqnarray*}
% Therefore, we actually have $\lambda_{1},\lambda_{2}\in\left\{ 0,1\right\} $,
% and there are only four projections: $0$, $\proj{0}$, $\proj{1}$,
% and $\mathbb{1}=\proj{0}+\proj{1}$. Then, $\mu_{\ket{\ps}}$ and
% $\mu_{\ket{\ms}}$ of each projections are 
% \[
% \begin{array}{c@{\qquad\qquad}c}
% \begin{array}{rcl}
% \mu_{\ket{\ps}}(0) & = & 0\\
% \mu_{\ket{\ps}}(\proj{0}) & = & 1/2\\
% \mu_{\ket{\ps}}(\proj{1}) & = & 1/2\\
% \mu_{\ket{\ps}}(\mathbb{1}) & = & 1
% \end{array} & \begin{array}{rcl}
% \mu_{\ket{\ms}}(0) & = & 0\\
% \mu_{\ket{\ms}}(\proj{0}) & = & 1/2\\
% \mu_{\ket{\ms}}(\proj{1}) & = & 1/2\\
% \mu_{\ket{\ms}}(\mathbb{1}) & = & 1
% \end{array}\end{array}
% \]
% Similarly, $\mu_{\ket{\ps}}$ and $\mu_{\ket{\ms}}$ gives two probability
% for family II as well.
% \[
% \begin{array}{c@{\qquad\qquad}c}
% \begin{array}{rcl}
% \mu_{\ket{\ps}}(0) & = & 0\\
% \mu_{\ket{\ps}}(\proj{+}) & = & 1\\
% \mu_{\ket{\ps}}(\proj{\ms}) & = & 0\\
% \mu_{\ket{\ps}}(\mathbb{1}) & = & 1
% \end{array} & \begin{array}{rcl}
% \mu_{\ket{\ms}}(0) & = & 0\\
% \mu_{\ket{\ms}}(\proj{\ps}) & = & 0\\
% \mu_{\ket{\ms}}(\proj{\ms}) & = & 1\\
% \mu_{\ket{\ms}}(\mathbb{1}) & = & 1
% \end{array}\end{array}
% \]

We now formalize a \emph{quantum probability space} as follows~\cite{BirkhoffVonNeumann1936,gleason1957,Redhead1987-REDINA,DBLP:journals/corr/abs-0910-2393,Maassen2010}.
We first assume an ambient Hilbert space~$\Hilb$ and define the
set of events $\qevents$ as all \emph{projections} on~$\Hilb$.
Each quantum state $\ket{\psi}\in\Hilb\backslash\left\{ 0\right\} $
induces a probability measure $\mu_{\psi}:\qevents\rightarrow[0,1]$
on the space of events defined for any event $E\in\qevents$ as follows\footnote{Recently, people extend the domain of $\mu_{\psi}$ to all operators~$\mathcal{A}$
on $\Hilb$ and consider $\mu_{\psi}:\mathcal{A}\rightarrow\C$~\cite{Maassen2010,Swart2013}.
When an operator $A\in\mathcal{A}$ is Hermitian, $\mu_{\psi}\left(A\right)$
is the expectation value of $A$. We does not take this approach because
we want to focus only on probability. }: 
\[
\mu_{\psi}(E)=\frac{\ip{\psi}{E\psi}}{\ip{\psi}{\psi}}
\]
Similarly to the classical case, this probability measure must satisfy:
\begin{itemize}
\item $\mu(\mathbb{1})=1$, and 
\item for a collection of pairwise orthogonal $E_i$, we have
  $\mu(\sum_i E_i) = \sum_i \mu(E_i)$. 

\yutsung{Claim: If $\sum_{i}\proj{\psi_{i}}$ is a projection, then
they are orthogonal. \\
Proof: If $\sum_{i}\proj{\psi_{i}}$ is a projection, then 
\begin{eqnarray*}
\ket{\psi_{j}} & = & \left(\sum_{i}\proj{\psi_{i}}\right)\ket{\psi_{j}}\\
 & = & \sum_{i}\ket{\psi_{i}}\ip{\psi_{i}}{\psi_{j}}
\end{eqnarray*}
Therefore, we have 
\begin{eqnarray*}
0 & = & \sum_{i\ne j}\ket{\psi_{i}}\ip{\psi_{i}}{\psi_{j}}
\end{eqnarray*}
} 
\end{itemize}

% \yutsung{If we follow \cite{Maassen2010,Swart2013}, then we also
% need 
% \begin{itemize}
% \item $\mu$ can be extended to a linear functional~$\mu:alg\left(\qevents\right)\rightarrow\mathbb{C}$,
% where $alg\left(\qevents\right)$ is the minimal $*$-algebra generated
% by $\qevents$.
% \end{itemize}
% Also, 
% \begin{itemize}
% \item for all $A\in\qevents$, we have $\mu(A^{*}A)\geq0$. 
% \end{itemize}
% should be 
% \begin{itemize}
% \item for all $A\in alg\left(\qevents\right)$, we have $\mu(A^{*}A)\geq0$. 
% \end{itemize}
% because we have $\mu(A^{*}A)=\mu(A^{2})=\mu(A)$ if $A$ is a projection.}\\

% \yutsung{$\left\{ \sum_{j=1}^{k}\lambda_{j}P_{j}~\middle|~\lambda_{1},\ldots,\lambda_{k}\in\mathbb{C}\right\} $
% is the minimal $*$-algebra generated by $P_{1},P_{2},\ldots,P_{k}$,
% but it contains all possible observables $P_{1},P_{2},\ldots,P_{k}$
% can generate (and something more) not just projections. For example,
% $2\mathbb{1}\in\left\{ \sum_{j=1}^{k}\lambda_{j}P_{j}~\middle|~\lambda_{1},\ldots,\lambda_{k}\in\mathbb{C}\right\} $.}\\

% \yutsung{So $\mu_{\psi}$ maps the projections generated by $P_{1},P_{2},\ldots,P_{k}$
% to $[0,1]$, and maps $\left\{ \sum_{j=1}^{k}\lambda_{j}P_{j}~\middle|~\lambda_{1},\ldots,\lambda_{k}\in\mathbb{C}\right\} $
% to $\mathbb{C}$...}\\


%%%%%
\subsection{Plan}

Several assumptions are woven in the definition of a quantum probability space:
\begin{itemize}
\item the Hilbert space $\Hilb$;
\item the real interval $[0,1]$; 
\item the fact that each state induces a probability measure, i.e., the
Born rule~\cite{Born1984,Mermin2007}; 
\item the fact that every probability measure is induced by a state, i.e.,
Gleason's theorem~\cite{gleason1957,peres1995quantum,Redhead1987-REDINA}. 
\end{itemize}
In the remainder of the paper, we examine each of these assumptions
and consider variations motivated by computation of numerical quantities in a
world with limited resources. In particular, we will consider a variant of the Hilbert
space over finite fields~$\mathbb{F}_{p^{2}}^{d}$~\cite{HansonOrtizSabryEtAl2015,DQT2014,geometry2013}. 

For the probability values, we will consider set-valued probability
measures~\cite{Artstein1972,PuriRalescu1983}, in particular $\mathscr{L}_{2}=\left\{ \textrm{impossible},\textrm{possible}\right\} $,
where impossible is a singleton set,$\left\{ 0\right\} $, and possible
is an open interval, $\left(0,\infty\right)$. Surprisingly, some
combinations of space and probability will result in an unique probability
measure. In these cases, there is no need to discuss whether there
is a Born rule, because we do not have enough probability to correspond
to every state.

If there may be more than one probability measure, we will discuss
whether there is a Born rule to generate a probability measure from
a state. When the space is $\mathbb{C}^{d}$, we will try to induced
a Born rule from the conventional Born rule. When the space is $\mathbb{F}_{p^{2}}^{d}$,
there is no natural way to induce a probability measure from a state,
so we will set some conditions for a Born rule~$\tilde{\pi}$: 
\begin{itemize}
\item Given a pure state $\ket{\Psi}\in\ffzd{p^{2}}$, a Born-rule~$\tilde{\pi}$
should give a probability~$\tilde{\pi}_{\Psi}$; 
\item $\ip{\Psi}{\Phi}=0\Leftrightarrow\tilde{\pi}_{\Psi}\left(\ket{\Phi}\right)=\tilde{0}$,
where $\tilde{0}$ is $0$ for $\left[0,1\right]$ and $\tilde{0}$
is impossible for $\mathscr{L}_{2}=\left\{ \textrm{impossible},\textrm{possible}\right\} $. 
\item $\tilde{\pi}_{\Psi}\left(\ket{\Phi}\right)=\tilde{\pi}_{\mathbf{U}\ket{\Psi}}\left(\mathbf{U}\ket{\Phi}\right)\textrm{ ,}$where
$\ket{\Psi},\ket{\Phi}\in\ffzd{p^{2}}$ and $\mathbf{U}$ is any unitary
map, i.e., $\mathbf{U}^{\dagger}\mathbf{U}=\mathbbm{1}$. 
\end{itemize}
Notice that when the space is $\mathbb{C}^{d}$, every Born rule we
consider will satisfy these three conditions.

Finally, if there is a Born rule, we will see whether every probability
measure is induced by a state, and establish Gleason's theorem. Notice
that Gleason's theorem only hold when $d\ge3$ in CQT so that we may
expect the situation for $d\ge3$ and $d=2$ are different. 

The results can be summarized in the following table:\\
\begin{tabular}{>{\raggedright}m{0.15\columnwidth}>{\raggedright}m{0.15\columnwidth}>{\raggedright}m{0.15\columnwidth}>{\raggedright}m{0.15\columnwidth}>{\raggedright}m{0.15\columnwidth}>{\raggedright}m{0.15\columnwidth}}
\hline 
State space $\Hilb$ & Probability values & How many probability measure? & Is there a nature Born rule? & How many possible Born rule if there is no nature one? & How many probability measure not come from any possible Born rules?\tabularnewline
\hline 
\hline 
$\C^{2}$ & $\left[0,1\right]$  & $\ge2$ & Yes &  & $\ge1$\tabularnewline
\hline 
$\C^{d}$ for $d\ge3$ & $\left[0,1\right]$  & $\ge2$ & Yes &  & $0$\tabularnewline
\hline 
$\C^{d}$ & $\mathscr{L}_{2}$ & $\ge2$ & Yes &  & $\ge1$\tabularnewline
\hline 
$\ff{3^{2}}^{d}$ for $3\ge d\ge2$ & $\left[0,1\right]$  & $\ge2$ & No & $1$ & $\ge1$\tabularnewline
\hline 
$\ff{p^{2}}^{2}$ for $p\ge7$ & $\left[0,1\right]$  & $\ge2$ & No & $\infty$ & $\ge1$\tabularnewline
\hline 
$\ff{7^{2}}^{3}$ & $\left[0,1\right]$  & $1$ & No & $0$ & \tabularnewline
\hline 
$\ffzd{p^{2}}$for $d\ge3$ except $d=p=3$ & $\left[0,1\right]$  & $\ge1$ 

(Whether $\ge2$ or $1$?) & No & $0$ & \tabularnewline
\hline 
$\ffzd{p^{2}}$ & $\mathscr{L}_{2}$ & $\ge2$ & No & $1$ & $\ge1$\tabularnewline
\hline 
\end{tabular}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{discreteGBKS}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Probability space (restricted to finite sample spaces)

* Sample space Ω (arbitrary finite non-empty set)
* Set of events F: pick 2^Ω
* Probability measure (real-valued): P : F → [0,1] such that:
  * For any collection of pairwise disjoint Aᵢ ∈ F, we have P ( ∪ᵢ Aᵢ) = ∑ᵢ P(Aᵢ) 
  * P(Ω) = 1


Set-value probability measures. Change the last bullet to:
* P : F → 2^(ℝⁿ) such that: ...

%%%%%
\subsection{Sample Space $\Omega$} 

In this paper, we will only consider \textbf{finite} sample spaces. We
therefore define a sample space $\Omega$ as a non-empty finite set.

\begin{example}[A Classical Sample Space.]
Consider an experiment that tosses three coins. A possible outcome of
the experiment is $HHT$ which means that the first and second coins
landed with ``heads'' as the face-up side and that the third coin
landed with ``tails'' as the face-up side. There are clearly a total
of eight possible outcomes, and this collection constitutes the sample
space:
\[
\Omega_C = \{ HHH, HHT, HTH, HTT, THH, THT, TTH, TTT \}
\]
\end{example}

\begin{example}[A Quantum Sample Space.]
Consider a quantum system composed of three electrons. By the
postulates of quantum mechanics, an experiment designed to measure
whether the spin of each electron along the $x$ axis is left ($L$) or
right ($R$) can only result in one of eight outcomes:
\[
\Omega_H = \{ LLL, LLR, LRL, LRR, RLL, RLR, RRL, RRR \}
\]
\end{example}

%%%%%
\subsection{Events $\mathcal{F}$} 

The space of events $\mathcal{F}$ associated with a sample space
$\Omega$ is $2^\Omega$, the powerset of $\Omega$. In other words,
every subset of $\Omega$ is a possible event.

\begin{example}[Some classical events.] 
The following are events associated with $\Omega_C$:
\begin{itemize}
\item $E_0$, exactly zero coins are $H$, is the set $\{ TTT \}$.
\item $E_1$, exactly one coin is $H$, is the set $\{ HTT, THT, TTH \}$. 
\item $E_2$, exactly two coins are $H$, is the set $\{ HHT, HTH, THH \}$.
\item $E_3$, exactly three coins are $H$, is the set $\{ HHH \}$. 
\item $E_{>0}$, at least one coin is $H$, is the set $\{ HHH, HHT, HTH, HTT, THH, THT, TTH \}$. 
\end{itemize}
As the examples illustrate, events are \emph{indirect} questions built from elementary elements of the sample space using logical connectives. Also
note that some events may be disjoint and that some events may be
expressed as combinations of other events. For example, we have
$E_{>0} = E_1 \cup E_2 \cup E_3$ and each of these four events is
disjoint from event $E_0$.
\end{example}

\begin{example}[Some quantum events.] 
The following are events associated with $\Omega_H$:
\begin{itemize}
\item $F_0$, exactly zero electrons are spinning $L$, is the set $\{ RRR \}$.
\item $F_1$, exactly one electron is spinning $L$, is the set $\{ LRR, RLR, RRL \}$. 
\item $F_2$, exactly two electrons are spinning $L$, is the set $\{ LLR, LRL, RLL \}$.
\item $F_3$, exactly three electrons are spinning $L$, is the set $\{ LLL \}$. 
\item $F_{>0}$, at least one electron is spinning $L$, is the set $\{ LLL, LLR, LRL, LRR, RLL, RLR, RRL \}$. 
\end{itemize}
As the examples illustrate, quantum events are, at first glance,
similar to classical events. There are however some subtle
differences that we point out in the next section.
\end{example}

%%%%%
\subsection{Measures $\mathbb{P}$} 

The last ingredient of a probability space is a probability measure
$\mathbb{P} : \mathcal{F} \rightarrow [0,1]$ that assigns to each
event a real number in the closed interval $[0,1]$ subject to the
following conditions:
\begin{itemize}
\item $\mathbb{P}(\Omega) = 1$, and 
\item For any collection of pairwise disjoint events $A_i$, we have 
$\mathbb{P}(\bigcup_i A_i) = \Sigma_i ~\mathbb{P}(A_i)$.
\end{itemize}

\begin{example}[Classical probability measure]
There are $2^8$ events associated with $\Omega_C$. A possible probability measure for
these events is:
\[\begin{array}{c}
\mathbb{P}(E) = \left\{ \begin{array}{ll} 
  1 & \mbox{if}~E = \Omega \\
  0 & \mbox{otherwise} 
  \end{array}\right.
\end{array}\]
\yutsung{ Actually, the above $\mathbb{P}$ is not a probability
measure because 
\[
\mathbb{P}\left(\Omega\right)=1\ne0+0=\mathbb{P}\left(E_{0}\right)+\mathbb{P}\left(E_{>0}\right)
\]
} \\
A more interesting measure is defined recursively as follows:
\renewcommand\arraystretch{1.4}
\[\begin{array}{rcl}
\mathbb{P}(\emptyset) &=& 0 \\
\mathbb{P}(\{ HHH \} \cup E) &=& \frac{1}{5} + \mathbb{P}(E) \\
\mathbb{P}(\{ HHT \} \cup E) &=& \mathbb{P}(E) \\
\mathbb{P}(\{ HTH \} \cup E) &=& \frac{3}{10} + \mathbb{P}(E) \\
\mathbb{P}(\{ HTT \} \cup E) &=& \mathbb{P}(E) \\
\mathbb{P}(\{ THH \} \cup E) &=& \frac{1}{5} + \mathbb{P}(E) \\
\mathbb{P}(\{ THT \} \cup E) &=& \mathbb{P}(E) \\
\mathbb{P}(\{ TTH \} \cup E) &=& \frac{3}{10} + \mathbb{P}(E) \\
\mathbb{P}(\{ TTT \} \cup E) &=& \mathbb{P}(E) 
\end{array}\]
\yutsung{Because $\mathbb{P}(\bigcup_{i}A_{i})=\Sigma_{i}~\mathbb{P}(A_{i})$
requires disjoint events, the above formula should write like:
\[
\begin{array}{rcl}
\mathbb{P}(\emptyset) & = & 0\\
\mathbb{P}(\{HHH\}\cup E) & = & \frac{1}{5}+\mathbb{P}(E)\textrm{, if }HHH\notin E\\
\mathbb{P}(\{HHT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }HHT\notin E\\
\mathbb{P}(\{HTH\}\cup E) & = & \frac{3}{10}+\mathbb{P}(E)\textrm{, if }HTH\notin E\\
\mathbb{P}(\{HTT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }HTT\notin E\\
\mathbb{P}(\{THH\}\cup E) & = & \frac{1}{5}+\mathbb{P}(E)\textrm{, if }THH\notin E\\
\mathbb{P}(\{THT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }THT\notin E\\
\mathbb{P}(\{TTH\}\cup E) & = & \frac{3}{10}+\mathbb{P}(E)\textrm{, if }TTH\notin E\\
\mathbb{P}(\{TTT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }TTT\notin E
\end{array}
\]
Or add a sentence ``where the element in the singleton set is not
belong to $E$ for each equation.'' Or write like: 
\[
\begin{array}{rcl}
\mathbb{P}(\{HHH\}) & = & \frac{1}{5}\\
\mathbb{P}(\{HHT\}) & = & 0\\
\mathbb{P}(\{HTH\}) & = & \frac{3}{10}\\
\mathbb{P}(\{HTT\}) & = & 0\\
\mathbb{P}(\{THH\}) & = & \frac{1}{5}\\
\mathbb{P}(\{THT\}) & = & 0\\
\mathbb{P}(\{TTH\}) & = & \frac{3}{10}\\
\mathbb{P}(\{TTT\}) & = & 0\\
\mathbb{P}(E) & = & \sum_{\omega\in E}\mathbb{P}(\left\{ \omega\right\} )
\end{array}
\]
} \\
Because this is a \emph{classical} situation, the probability
assignments can be understood \emph{locally} and
\emph{non-contextually}. In other words, we can reason about each coin
separately and perform experiments on it ignoring the rest of the
context. If we were to perform such experiments we may find that for
the first coin, the probability of either outcome
$H$ or $T$ is $\frac{1}{2}$; for coin two, the probabilities are
skewed a little with the probability of outcome $H$ being
$\frac{2}{5}$ and the probability of outcome $T$ being $\frac{3}{5}$; and that
coin 3 is a fake double-headed coin where the probability of
outcome $H$ is 1 and the probability of outcome $T$ is 0. The reader
may check that these local observations are consistent with the
probability measure above. 
\end{example}

\begin{example}{[}Quantum probability measure{]} Like in the classical
case, there are $2^{8}$ events. But as Mermin explains in a simple
example~\cite{MerminPRL1990}, here is a possible probability measure:
\[
\begin{array}{rcl}
\mathbb{P}_{xxx}(\{LLL\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{LLR\}) & = & 0\\
\mathbb{P}_{xxx}(\{LRL\}) & = & 0\\
\mathbb{P}_{xxx}(\{LRR\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{RLL\}) & = & 0\\
\mathbb{P}_{xxx}(\{RLR\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{RRL\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{RRR\}) & = & 0\\
\mathbb{P}_{xxx}(E) & = & \sum_{\omega\in E}\mathbb{P}_{xxx}(\left\{ \omega\right\} )
\end{array}
\]
In contrast with the previous classical example, the event of different
electrons are not independent. More precisely, consider the event
for each electron separately:
\begin{eqnarray*}
F_{1,L} & = & \left\{ LLL,LLR,LRL,LRR\right\} \\
F_{2,L} & = & \left\{ LLL,LLR,RLL,RLR\right\} \\
F_{3,L} & = & \left\{ LLL,LRL,RLL,RRL\right\} 
\end{eqnarray*}
They are not independent means 
\[
\mathbb{P}_{xxx}(F_{1,L}\cap F_{2,L}\cap F_{3,L})=\mathbb{P}_{xxx}(\{LLL\})=\frac{1}{4}\ne\frac{1}{8}=\mathbb{P}_{xxx}(F_{1,L})\mathbb{P}_{xxx}(F_{2,L})\mathbb{P}_{xxx}(F_{3,L})\textrm{ .}
\]


Classical events may also not be independent even if they seems unrelated.
For example, events defined by the temperature is usually not independent
to ones defined by how much Coca-Cola is sold. Another example can
be formulated by tossing three coins as we discussed previously. However,
this time the coins are tossed behind a veil where someone tosses
the coins for you. Because we cannot see how she tosses the coins,
she might actually roll a four-sided tetrahedral die with $\{HHH,HTT,THT,TTH\}$
in its four faces. If $HTT$ is on the downward face, she places $H$,
$T$, and $T$ as the face-up sides of of the three coins by hand,
respectively. Then, she uncovers the veil, and claims she has tossed
the coins. If the coins are tossed in this way, the result of coin-tossing
is correlated, and we will never see $TTT$ no matter how many times
we toss these coins. 

Because we do not know how the spin of an electron is decided, Einstein,
Podolsky, and Rosen (EPR)~\cite{EPR1935} suggested the nature might
give us the probability measure~$\mathbb{P}_{xxx}$ because she rolled
a tetrahedral die or performed other classical and deterministic process
behind the veil. This claim may be convincing if $\mathbb{P}_{xxx}$
is the only probability measure we have, but will lead to a contradiction
if we consider other probability measures as well. Notice that after
the coins are placed by hand and before uncovering the veil, which
side up has already been decided although we do not know. This would
be also true for the quantum probability measure. Because the three
electrons can be spatially separated, and each electron can be measured
along the $x$ axis separately, if the nature rolled a tetrahedral
die, this die should be rolled before the electrons are separated
and measured, and she should know the result of measurement before
we measure the electrons. Let the result of the $j$-th electron measured
along the $x$ axis be $w\left(\sigma_{x}^{j}\right)$. Because 
\[
\mathbb{P}_{xxx}(\{LLR\})=\mathbb{P}_{xxx}(\{LRL\})=\mathbb{P}_{xxx}(\{RLL\})=\mathbb{P}_{xxx}(\{RRR\})=0\textrm{ ,}
\]
we have $w\left(\sigma_{x}^{1}\right)w\left(\sigma_{x}^{2}\right)w\left(\sigma_{x}^{3}\right)\in\{LLL,LRR,RLR,RRL\}$,
i.e., the number of $L$ in $w\left(\sigma_{x}^{1}\right)$, $w\left(\sigma_{x}^{2}\right)$,
and $w\left(\sigma_{x}^{3}\right)$ should be odd. 

The three electrons cannot be measured the spin only along the $x$
axis, but also along the $y$ axis with the result down ($D$) or
up ($U$). We only consider to measure even number of electrons along
the $y$ axis, and the probability measures could be defined by 
\begin{eqnarray*}
\begin{array}{rcl}
\mathbb{P}_{xyy}(\{LDD\}) & = & 0\\
\mathbb{P}_{xyy}(\{LDU\}) & = & \frac{1}{4}\\
\mathbb{P}_{xyy}(\{LUD\}) & = & \frac{1}{4}\\
\mathbb{P}_{xyy}(\{LUU\}) & = & 0\\
\mathbb{P}_{xyy}(\{RDD\}) & = & \frac{1}{4}\\
\mathbb{P}_{xyy}(\{RDU\}) & = & 0\\
\mathbb{P}_{xyy}(\{RUD\}) & = & 0\\
\mathbb{P}_{xyy}(\{RUU\}) & = & \frac{1}{4}
\end{array} & \begin{array}{rcl}
\mathbb{P}_{yxy}(\{DLD\}) & = & 0\\
\mathbb{P}_{yxy}(\{DLU\}) & = & \frac{1}{4}\\
\mathbb{P}_{yxy}(\{DRD\}) & = & \frac{1}{4}\\
\mathbb{P}_{yxy}(\{DRU\}) & = & 0\\
\mathbb{P}_{yxy}(\{ULD\}) & = & \frac{1}{4}\\
\mathbb{P}_{yxy}(\{ULU\}) & = & 0\\
\mathbb{P}_{yxy}(\{URD\}) & = & 0\\
\mathbb{P}_{yxy}(\{URU\}) & = & \frac{1}{4}
\end{array} & \begin{array}{rcl}
\mathbb{P}_{yyx}(\{DDL\}) & = & 0\\
\mathbb{P}_{yyx}(\{DDR\}) & = & \frac{1}{4}\\
\mathbb{P}_{yyx}(\{DUL\}) & = & \frac{1}{4}\\
\mathbb{P}_{yyx}(\{DUR\}) & = & 0\\
\mathbb{P}_{yyx}(\{UDL\}) & = & \frac{1}{4}\\
\mathbb{P}_{yyx}(\{UDR\}) & = & 0\\
\mathbb{P}_{yyx}(\{UUL\}) & = & 0\\
\mathbb{P}_{yyx}(\{UUR\}) & = & \frac{1}{4}
\end{array}
\end{eqnarray*}
with $\mathbb{P}_{ijk}(E)=\sum_{\omega\in E}\mathbb{P}_{ijk}(\left\{ \omega\right\} )$.
Similarly, the nature should predetermine $w\left(\sigma_{x}^{j}\right)$
and $w\left(\sigma_{y}^{j}\right)$ for them. Furthermore, because
she do not know along which axis we are going to measure, she should
predetermine the same $w\left(\sigma_{x}^{j}\right)$ and $w\left(\sigma_{y}^{j}\right)$
for all different probability measures. By the same reason as above,
the number of $L$ or $D$ in $\left\{ w\left(\sigma_{x}^{1}\right),w\left(\sigma_{y}^{2}\right),w\left(\sigma_{y}^{3}\right)\right\} $,
$\left\{ w\left(\sigma_{y}^{1}\right),w\left(\sigma_{x}^{2}\right),w\left(\sigma_{y}^{3}\right)\right\} $,
and $\left\{ w\left(\sigma_{y}^{1}\right),w\left(\sigma_{y}^{2}\right),w\left(\sigma_{x}^{3}\right)\right\} $
should be even. If we look these 9 letters carefully, we can find
that every $w\left(\sigma_{x}^{j}\right)$ appears once and every
$w\left(\sigma_{y}^{j}\right)$ appears twice. Hence, the number of
$L$ in $w\left(\sigma_{x}^{1}\right)$, $w\left(\sigma_{x}^{2}\right)$,
and $w\left(\sigma_{x}^{3}\right)$ should be even. This contradict
to the conclusion in our last paragraph. Therefore, EPR's assumption
is wrong, and it is not always true that the nature can predetermine
the measurement result before we perform the measurement. \end{example}


%%%%
\subsection{Finite Precision of Measurements}

In a laboratory setting or a computational setting, there are neither
uncountable entities nor uncomputable entities. We are thus looking at
alternative probability spaces which do not depend on the real numbers
and revisit the mysteries of quantum mechanics in that
setting. In other words, is it possible that at least part of the quantum mysteries related to probability and measurement are due to the reliance on uncomputable probability values? 

Following previous work on probability, we will replace the
closed interval $[0,1]$ by the \emph{finite set} $S = \{
\textbf{possible}, \textbf{impossible} \}$ and adapt the definition of
probability measure as follows.

A set-valued probability measure $\mathbb{P} : \mathcal{F} \rightarrow
S$ assigns to each event either the tag \textbf{possible} or the tag
\textbf{impossible} subject to the following conditions:
\begin{itemize}
\item $\mathbb{P}(\Omega) = \textbf{possible}$, and 
\item For any collection of pairwise disjoint events $A_i$, we have 
$\mathbb{P}(\bigcup_i A_i) = \textbf{possible}$ if any event $A_i$ is
\textbf{possible} and \textbf{impossible} otherwise. 
\end{itemize}

We begin by reviewing the conventional presentation of classical
probability spaces and then give an alternative formulation that is
``quantum-like'' but still classical. We conclude this section with a
definition of quantum probability spaces given as a modest
generalization of the alternative classical definition. 

%%%%%
\subsection{Conventional Classical Probability Spaces}

Textbook probability
theory~\cite{inun.425605319950101,GrahamKnuthPatashnik1994,rohatgi2011introduction}
is defined using the notions of a \emph{sample space} $\Omega$, a
space of \emph{events}~$\events$, and a \emph{probability
  measure}~$\pmeas$. In this paper, we will only consider
\emph{finite} sample spaces: we therefore define a sample space
$\Omega$ as an arbitrary non-empty finite set and the space of events
$\events$ as, $2^\Omega$, the powerset of $\Omega$. A \emph{probability
measure} is a function $\pmeas : \events \rightarrow [0,1]$ such that:
\begin{itemize}
\item $\pmeas(\Omega) = 1$, and 
\item for a collection of pairwise disjoint events $E_i$, we have
  $\pmeas(\bigcup E_i) = \sum \pmeas(E_i)$. 
\end{itemize}

\begin{example}[Two coin experiment] Consider an experiment that
  tosses two coins. We have four possible outcomes that constitute the
  sample space $\Omega = \{ HH, HT, TH, TT \}$. The event that the
  first coin is ``heads'' is $\{ HH, HT \}$; the event that the two
  coins land on opposite sides is $\{ HT, TH \}$; the event that at
  least one coin is tails is $\{ HT, TH, TT\}$. Depending on the
  assumptions regarding the coins, we can define several probability
  measures. Here is a possible one:
\[\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\pmeas(\emptyset) &=& 0 \\
\pmeas(\{ HH \}) &=& 1/3 \\
\pmeas(\{ HT \}) &=& 0 \\
\pmeas(\{ TH \}) &=& 2/3 \\
\pmeas(\{ TT \}) &=& 0 \\
\pmeas(\{  HH, HT \}) &=& 1/3 \\
\pmeas(\{  HH, TH \}) &=& 1 \\
\pmeas(\{  HH , TT \}) &=& 1/3 
\end{array} & \begin{array}{rcl}
\pmeas(\{  HT, TH \}) &=& 2/3 \\
\pmeas(\{  HT , TT \}) &=& 0 \\
\pmeas(\{  TH , TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH \}) &=& 1 \\
\pmeas(\{  HH, HT, TT \}) &=& 1/3 \\
\pmeas(\{  HH, TH, TT \}) &=& 1 \\
\pmeas(\{  HT, TH, TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH, TT \}) &=& 1
\end{array}
\end{array}\]
\end{example}

%%%%%
\subsection{Alternative Definition of Classical Probability Spaces}

In the conventional presentation, we have viewed the space of events
$2^\Omega$ are the powerset of $\Omega$. We can equivalently view
$2^\Omega$ as the space of functions from $\Omega$ to the set
$2 = \{0,1\}$. For example, the event $\{HT,TH\}$ is the function $e$
such that:
\[
e (HH) = 0, \quad e (HT) = 1, \quad e (TH) = 1, \quad e (TT) = 0 
\]
We will in fact do a sweeping generalization and view events as
functions from $\Omega$ to $\mathbb{C}$, the set of complex
numbers. This accommodates the previous events such as $e$ and allows
many more events such as event $e'$ below:
\[
e' (HH) = \sqrt{2} + i \sqrt{3}, \quad e' (HT) = 1, \quad e' (TH) = \pi, \quad e' (TT) = 0 
\]
The events are not going to be completely arbitrary functions,
however. We will insist on some conditions:...

This generalization

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conventional Quantum Mechanics}

Attempting to modify the probability measure to be set-valued, while keeping the rest of the mathematical framework of quantum mechanics intact leads to a contradiction. More precisely, it is not possible to maintain infinite precision probability amplitudes in the presence of set-valued probabilities without violating essential aspects of quantum theory. 

\ldots explain and give theorem

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discrete Quantum Theory}

The next question to ask is therefore whether the infinite precision of probability amplitudes is itself justified. If all measurements are finite and all probabilities are computable, then it is plausible that the internal mathematical representation of quantum states should also be based on countable computable entities. 
