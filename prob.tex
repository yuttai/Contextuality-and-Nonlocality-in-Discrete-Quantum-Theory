\documentclass{article}
\usepackage{fullpage}
\usepackage{url}
\usepackage{bbm}
\usepackage{bbold}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{array}
\usepackage{mathrsfs}
\usepackage[all]{xy}
\usepackage{amsmath}
\usepackage{wesa}
\usepackage[T1]{fontenc}

\makeatletter
\newtheoremstyle{indented}
  {3pt}% space before
  {3pt}% space after
  {\addtolength{\@totalleftmargin}{3.5em}
   \addtolength{\linewidth}{-3.5em}
   \parshape 1 3.5em \linewidth}% body font
  {}% indent
  {\bfseries}% header font
  {.}% punctuation
  {.5em}% after theorem header
  {}% header specification (empty for default)
\makeatother
\theoremstyle{indented}
%% \theoremstyle{remark}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newcommand{\events}{\ensuremath{\mathcal{E}}}
\newcommand{\qevents}{\ensuremath{\mathcal{E}}}
\newcommand{\pmeas}{\ensuremath{\mu}}
\newcommand{\Hilb}{\mathcal{H}}
\newcommand{\pr}[2]{\langle #1, #2 \rangle}
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\ip}[2]{\langle #1 | #2 \rangle}
\newcommand{\proj}[1]{|#1 \rangle\langle #1 |}
\newcommand{\ps}{\texttt{+}}
\newcommand{\ms}{\texttt{-}}
\newcommand{\poss}{{\mbox{\wesa{possible}}}}
\newcommand{\imposs}{{\mbox{\wesa{impossible}}}}

\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\newcommand{\yutsung}[1]{\fbox{\begin{minipage}{0.9\textwidth}\color{purple}{Yu-Tsung says: #1}\end{minipage}}}
\newcommand{\amr}[1]{\fbox{\begin{minipage}{0.9\textwidth}\color{green}{Amr says: #1}\end{minipage}}}
\newcommand{\ffzd}[1]{{\mathbb{F}^{d\;*}_{#1}}}
\def\C{{\mathbb{C}}}
\newcommand{\ff}[1]{\mathbb{F}_{#1}}
\newcommand{\melement}[2]{ \langle #1 | #2 | #1 \rangle}
\newcommand{\expect}[2]{ \langle #1 | #2 | #1 \rangle}
\newcommand{\Tr}{\mathop{\mathrm{Tr}}\nolimits}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}
\theoremstyle{plain}
\newtheorem{cor}[thm]{Corollary}

\begin{document}
\title{Probability}
\author{}
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classical Probability Spaces}
 
A \emph{probability
  space}~\cite{inun.425605319950101,GrahamKnuthPatashnik1994,rohatgi2011introduction}
specifies the necessary conditions for reasoning coherently about
collections of uncertain events. It consists of a \emph{sample space}
$\Omega$, a space of \emph{events}~$\events$, and a \emph{probability
  measure}~$\pmeas$. In this paper, we will only consider
\emph{finite} sets of events: we therefore define a sample space
$\Omega$ as an arbitrary non-empty finite set and the space of events
$\events$ as $2^\Omega$, the powerset of $\Omega$. Given the set of
events $\events$, a \emph{probability measure} is a function
$\pmeas : \events \rightarrow [0,1]$ such that:
\begin{itemize}
\item $\pmeas(\Omega) = 1$, and 
\item for a collection $E_i$,  of pairwise disjoint events, 
  $\pmeas(\bigcup E_i) = \sum \pmeas(E_i)$.
\end{itemize}

\begin{example}[Two-coin probability space]
  Consider an experiment that tosses two coins. We have four possible
  outcomes that constitute the sample space
  $\Omega = \{ HH, HT, TH, TT \}$. There are 16 total events including
  for example the event $\{ HH, HT \}$ that the first coin is
  ``heads,'' the event $\{ HT, TH \}$ that the two coins land on
  opposite sides, and the event $\{ HT, TH, TT\}$ that at least one
  coin is tails. Here is a possible probability measure for these
  events:
\[\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\pmeas(\emptyset) &=& 0 \\
\pmeas(\{ HH \}) &=& 1/3 \\
\pmeas(\{ HT \}) &=& 0 \\
\pmeas(\{ TH \}) &=& 2/3 \\
\pmeas(\{ TT \}) &=& 0 \\
\pmeas(\{  HH, HT \}) &=& 1/3 \\
\pmeas(\{  HH, TH \}) &=& 1 \\
\pmeas(\{  HH , TT \}) &=& 1/3 
\end{array} & \begin{array}{rcl}
\pmeas(\{  HT, TH \}) &=& 2/3 \\
\pmeas(\{  HT , TT \}) &=& 0 \\
\pmeas(\{  TH , TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH \}) &=& 1 \\
\pmeas(\{  HH, HT, TT \}) &=& 1/3 \\
\pmeas(\{  HH, TH, TT \}) &=& 1 \\
\pmeas(\{  HT, TH, TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH, TT \}) &=& 1
\end{array}
\end{array}\]
The assignment satisfies the two constraints for probability measures:
the probability of the entire sample space is 1, and the probability
of every collection of disjoint events (e.g.,
$\{ HT, TH \} = \{ HT \} \cup \{ TH \}$) is the sum of the individual
probabilities. The probability of collections of non-disjoint events
(e.g., $\{ HT, TH, TT \} = \{ HT, TH \} \cup \{ TH , TT \}$) may add
to something different than the probabilities of the individual
events. It is useful to think that this probability measure is
completely induced by the two coins and their characteristics in the
sense that each pair of coins induces a measure, and each measure must
correspond to some pair of coins.
\qed\end{example}

In a strict computational or experimental setting, one may question
the reliance of the definition of probability space on the uncountable
and uncomputable real interval $[0,1]$. This interval includes numbers
like $0.h_1h_2h_3\ldots$ where $h_i$ is 1 or 0 depending on whether
Turing machine $M_i$ halts or not. Such numbers cannot be
computed. This interval also includes numbers like $\frac{\pi}{4}$
which can only be computed with increasingly large resources as the
precision increases.
% \yutsung{Check the meaning of the ``computing $\frac{\pi}{4}$'', because
% Bailey Borwein Plouffe formula can computing the $n$th binary digit of $\pi$ 
% using base 16 directly.}
Therefore, in a resource-aware setting, it is more appropriate to
consider probability measures that map events to a finite set of
elements computable with a fixed set of
resources~\cite{Artstein1972,PuriRalescu1983}. The simplest such set,
and the one we will consider exclusively in this paper, is the set
$\mathscr{L}_{2}=\left\{ \imposs, \poss\right\}$ together with the
operation $\vee$ where $x \vee y=\imposs$ if and only if
$x=y=\imposs$. In relation to the first definition, one can interpret
\imposs\ as the closed interval $[0,0]$, \poss\ as the half-open
interval $(0,1]$, and $\vee$ as the addition of intervals. The
definition of a probability measure in this case is modified as being
a function $\pmeas : \events \rightarrow \mathscr{L}_{2}$ such that:
\begin{itemize}
\item $\pmeas(\Omega) = \poss$, and
\item for a collection $E_i$,  of pairwise disjoint events, $\pmeas(\bigcup E_i) = \bigvee \pmeas(E_i)$.
\end{itemize}

\begin{example}[Two-coin probability space with finite set-valued
  probability measure] Under the new set-valued requirement, the
  probability measure in the first example becomes:
\[\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\pmeas(\emptyset) &=& \imposs \\
\pmeas(\{ HH \}) &=& \poss \\
\pmeas(\{ HT \}) &=& \imposs \\
\pmeas(\{ TH \}) &=& \poss \\
\pmeas(\{ TT \}) &=& \imposs \\
\pmeas(\{  HH, HT \}) &=& \poss \\
\pmeas(\{  HH, TH \}) &=& \poss \\
\pmeas(\{  HH , TT \}) &=& \poss \\
\end{array} & \begin{array}{rcl}
\pmeas(\{  HT, TH \}) &=& \poss \\
\pmeas(\{  HT , TT \}) &=& \imposs \\
\pmeas(\{  TH , TT \}) &=& \poss \\
\pmeas(\{  HH, HT, TH \}) &=& \poss \\
\pmeas(\{  HH, HT, TT \}) &=& \poss \\
\pmeas(\{  HH, TH, TT \}) &=& \poss \\
\pmeas(\{  HT, TH, TT \}) &=& \poss \\
\pmeas(\{  HH, HT, TH, TT \}) &=& \poss 
\end{array}
\end{array}\]
\qed\end{example}

We will return to finite set-valued probability measures in Sec.~\ref{sec:?}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quantum Probability Spaces}

The mathematical framework above assumes that one has complete
knowledge of the events and their relationships. However, in many
practical situations, the structure of the event space is only
partially known and the precise dependence of two events on each other
cannot, a priori, be determined with certainty. In the quantum case,
this partial knowledge is compounded by the fact that there exist
non-commuting events which cannot happen simultaneously. To
accommodate these more complex situations, we abandon the sample
space~$\Omega$ and reason directly about events. A quantum probability
space therefore consist of just two components: a set of events
$\qevents$ and a probability measure
$\mu : \qevents \rightarrow [0,1]$. We give an example before giving
the formal definition.

\begin{example}[One-qubit quantum probability space] 
  Consider a one-qubit Hilbert space with states
  $\alpha \ket{0} + \beta \ket{1}$ such that
  $|\alpha|^2 + |\beta|^2 = 1$. The set of events associated with this
  Hilbert space consists of the empty projection~$\mathbb{0}$ together 
  with projection operators $\proj{\psi}$ for each state $\ket{\psi}$.
  Each event is interpreted as a possible post-measurement state of a
  quantum system in current state $\ket{\phi}$. For example, the event
  $\proj{0}$ indicates that the post-measurement state will
  be~$\ket{0}$; the event $\proj{1}$ indicates that the
  post-measurement state will be~$\ket{1}$; the event $\proj{\ps}$
  where $\ket{\ps} = \frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$ indicates
  that the post-measurement state will be $\ket{\ps}$; the event
  $\mathbb{1} = \proj{0}+\proj{1}$ indicates that the post-measurement
  state will be a linear combination of $\ket{0}$ and $\ket{1}$; and
  the event $\mathbb{0}$ states that the post-measurement state will
  be the empty state. As in the classical case, a probability measure
  maps events to $[0,1]$: here is a partial specification of a
  possible measure:
\[\begin{array}{rcl}
\mu\left(\mathbb{0}\right) = 0, \quad
\mu\left(\mathbb{1}\right) =  1, \quad
\mu\left(\proj{0}\right) = 1, \quad
\mu\left(\proj{1}\right) = 0, \quad
\mu\left(\proj{\ps}\right) = 1/2, \quad \ldots
\end{array}\]
Note that, similarly to the classical case, the probability of
$\mathbb{1}$ is 1 and the probability of collections of orthogonal
events (e.g., $\proj{0}+\proj{1}$) is the sum of the individual
probabilities. In contrast, a collection of non-orthogonal events
(e.g., $\proj{0}$ and $\proj{\ps}$) is not itself an event.
In the classical example, we argued that each probability measure is
uniquely determined by two actual coins. A similar (but much more
subtle) argument is valid also in the quantum case. By postulates of
quantum mechanics and Gleason's theorem, it turns out that for large
enough quantum systems, each probability measure is uniquely
determined by an actual quantum state.
\qed\end{example}

To properly explain the previous example and generalize to arbitrary
quantum systems, we formally discuss projection operators and then
define a quantum probability space. 

\amr{ 

  Projections include $\mathbb{0}, \proj{\psi}$ and $P_1 + P_2$ and
  $P_1 . P_2$ if $P_1$ and $P_2$ commute.

  When we write an event as $\sum E_i$ we are implicitly assuming they
  are commutative.

  Orthogonal implies commutative but not vice-versa
}

\begin{definition}[Quantum Probability Space~\cite{BirkhoffVonNeumann1936,gleason1957,Redhead1987-REDINA,DBLP:journals/corr/abs-0910-2393,Maassen2010}]
  Given a Hilbert space $\Hilb$, a \emph{quantum probability space}
  consists of a set of events $\events$ and a probability measure
  $\mu : \events \rightarrow [0,1]$ such that:\footnote {It is
    possible to define a more general space of events consisting of
    all operators~$\mathcal{A}$ on $\Hilb$ and consider
    $\mu:\mathcal{A}\rightarrow\C$~\cite{Maassen2010,Swart2013}.  When
    an operator $A\in\mathcal{A}$ is Hermitian, $\mu\left(A\right)$ is
    the expectation value of $A$. We does not take this approach
    because we want to focus only on probability. }
\begin{itemize}
\item The set of events consists of all projections. This set includes
  the empty projection, projection operators $\proj{\psi}$ for each
  state $\ket{\psi}$, and sums of \emph{commuting} projections, 
\item $\mu(\mathbb{1})=1$, and 
\item for mutually orthogonal projections $E_i$, we have
  $\mu\left(\sum_{i}E_{i}\right)=\sum_{i}\mu\left(E_{i}\right)$.
\end{itemize}
\qed\end{definition}

%% See http://math.stackexchange.com/questions/1146893/on-the-sum-of-projection-operators
% Two properties: E1 orthogonal to E2 or not
%                          E1 commutative with E2 or not

% the empty projection $\mathbb{0}$

%   \yutsung{and the sum of the orthogonal events recursively.}


%%%%%
\subsection{Quantum Probability Measures}

For a given set of events $\events$, there are many possible
probability measures $\mu : \events \rightarrow [0,1]$. The Born rule,
a postulate of quantum mechanics, states that each quantum state
$\ket{\phi}$ induces a probability measure $\mu_\phi$ as follows:
\[ 
\mu_\phi(E) = \ip{\phi}{E\phi}
\]
Conversely, Gleason's theorem states that given a probability measure
$\mu$, there exist a quantum state $\ket{\phi}$ that induces such a
measure using the Born rule. The theorem is only valid in Hilbert
spaces with dimension $d \geq 3$. It is instructive to study
counterexamples in $d=2$, i.e., the case of a one-qubit
system. Consider five states $\ket{\psi_0}$ to $\ket{\psi_4}$ that
form five orthogonal bases $\{ \ket{\psi_0}, \ket{\psi_1} \}$,
$\{ \ket{\psi_1}, \ket{\psi_2} \}$,
$\{ \ket{\psi_2}, \ket{\psi_3} \}$,
$\{ \ket{\psi_3}, \ket{\psi_4} \}$, and
$\{ \ket{\psi_4}, \ket{\psi_0} \}$ and consider the probability
measure defined as follows. For all $i \in \{0,1,2,3,4\}$, we have
$\mu_X(\proj{\psi_i}) = 1/2$. For each orthogonal basis, the
probability is 1 as desired and yet it is impossible to find a single
quantum state that realizes such a probability
measure (see \url{http://tph.tuwien.ac.at/~svozil/publ/2006-gleason.pdf})

\newpage
\amr{the rest needs cleaning up and perhaps does not even belong in
  this section}

Although it seems that we need an infinite long table to specify the
quantum probability measure~$\mu$, our $\mu$ is actually
given by a simple formula~$\melement{0}{E}$. In general, Born discovered
each quantum state $\ket{\psi}\in\Hilb\backslash\left\{ 0\right\} $
induces a probability measure $\tilde{\mu}_{\psi}:\qevents\rightarrow[0,1]$
on the space of events defined for any event $E\in\qevents$ as follows~\cite{Born1984,Mermin2007}:
\begin{equation}
\tilde{\mu}_{\psi}(E)=\frac{\melement{\psi}{E}}{\ip{\psi}{\psi}}\label{eq:Born}
\end{equation}
The Born rule satisfies the following properties:
\begin{itemize}
\item It can be extend to mixed states. Given a mixed state represented
by a density matrix $\rho=\sum_{j=1}^{N}q_{j}\frac{\proj{\psi_{j}}}{\ip{\psi_{j}}{\psi_{j}}}$,
where $\sum_{j=1}^{N}q_{j}=1$, i.e., $\Tr\left(\rho\right)=1$, then
the Born rule can be extended to $\rho$ by 
\begin{eqnarray}
\tilde{\mu}_{\rho}\left(E\right) & = & \Tr\left(\rho E\right)=\sum_{j=1}^{N}q_{j}\tilde{\mu}_{\Psi_{j}}\left(E\right)\textrm{ .}\label{BornRule.mixed}
\end{eqnarray}
Notice that $\left(\left\{ 1,\ldots,N\right\} ,2^{\left\{ 1,\ldots,N\right\} },\pmeas\left(J\right)=\sum_{j\in J}q_{j}\right)$
is a classical probability space. Therefore, when we discretize the
Hilbert space later, we may need to discretize this probability space
as well.
\item $\tilde{\mu}_{\rho}$ is a probability measure for all mixed state~$\rho$.
\item $\ip{\psi}{\phi}=0\Leftrightarrow\tilde{\mu}_{\psi}\left(\proj{\phi}\right)=0$.
\item $\tilde{\mu}_{\psi}\left(E\right)=\tilde{\mu}_{\mathbf{U}\ket{\psi}}\left(\mathbf{U}E\mathbf{U}^{\dagger}\right)\textrm{ ,}$where
$\mathbf{U}$ is any unitary map, i.e., $\mathbf{U}^{\dagger}\mathbf{U}=\mathbb{1}$. 
\end{itemize}

Naturally, we may ask: is every probability measure induced from a
state by the Born rule? The answer is yes by Gleason's theorem when
the dimension~$\ge3$~\cite{gleason1957,peres1995quantum,Redhead1987-REDINA}.
Furthermore, a simple corollary of Gleason's theorem can show the
Born rule is the unique function satisfying conditions 1. to 3.
\begin{cor}
The Born rule is the unique function satisfying conditions 1. to 3.
\end{cor}
\begin{proof}
Assume there is another function $\tilde{\mu}'$ such that $\tilde{\mu}'_{\rho}$
is a quantum probability measure for all mixed state~$\rho$. We
are going to prove $\tilde{\mu}'=\tilde{\mu}$.

Fix a pure normalized state $\phi$, $\tilde{\mu}'_{\phi}$ is a quantum
probability measure by condition 2. By Gleason's theorem, there is
a mixed state ~$\rho'$, such that $\tilde{\mu}'_{\phi}\left(E\right)=\Tr\left(\rho'E\right)=\sum_{j=1}^{N}q_{j}\tilde{\mu}_{\psi_{j}}\left(E\right)$
for all event $E$. 

Consider the event $E'=\mathbb{1}-\proj{\phi}$, we have 
\begin{eqnarray*}
0 & \overset{\textrm{Condition 3}}{=} & \tilde{\mu}_{\phi}\left(E'\right)\\
 & = & \sum_{j=1}^{N}q_{j}\tilde{\mu}_{\psi_{j}}\left(E'\right)
\end{eqnarray*}
Because $q_{j}>0$, we have $\tilde{\mu}_{\psi_{j}}\left(E\right)=0$,
i.e., $\psi_{j}$ is orthogonal to a co-dimension-$1$ subspace $E'$.
However, the only subspace orthogonal to $E'$ is span by $\ket{\phi}$.
Hence, $\tilde{\mu}'_{\phi}=\tilde{\mu}_{\phi}$.
\end{proof}

\amr{give example non-commuting events}

\yutsung{Isn't $\proj{0}$ and $\proj{\ps}$ an example in the example of
One-qubit quantum probability space.}

%%%%%
\subsection{Plan}

In the remainder of the paper, we consider variations of quantum
probability spaces motivated by computation of numerical quantities in
a world with limited resources:
\begin{itemize}
\item Instead of the Hilbert space $\Hilb$ (constructed over the
  uncountable and uncomputable complex numbers $\mathbb{C}$), we will
  consider variants constructed over finite
  fields~\cite{HansonOrtizSabryEtAl2015,DQT2014,geometry2013}.
\item Instead of real-valued probability measures producing results in
  the uncountable and uncomputable interval $[0,1]$, we will consider
  finite set-valued probability measures~\cite{Artstein1972,PuriRalescu1983}.
\end{itemize}
We will then ask if it is possible to construct variants of quantum
probability spaces under these conditions. The main question is
related to the definition of probability measures: is it possible to
still define a probability measure as a function that depends on a
single state? Specifically,
\begin{itemize}
\item given a state $\ket{\psi}$, is there a probability measure
  mapping events to probabilities that only depends on $\ket{\psi}$?
  In the conventional quantum probability space, the answer is yes by
  the Born rule~\cite{Born1984,Mermin2007} and the map is given by:
  $E \mapsto \ip{\psi}{E\psi}$.
\item given a probability measure $\mu$
  mapping each event $E$
  to a probability, is there a \emph{unique} state $\psi$
  such that $\mu(E)
  =
  \ip{\psi}{E\psi}$? In the conventional case, the answer is yes by
  Gleason's
  theorem~\cite{gleason1957,peres1995quantum,Redhead1987-REDINA}.
\end{itemize}


% If there may be more than one probability measure, we will discuss
% whether we will keep using the Born rule (\ref{eq:Born}) or there
% is another formula $\tilde{\mu}$ such that $\tilde{\mu}_{\psi}$
% is a probability measure for all $\ket{\psi}\in\Hilb\backslash\left\{ 0\right\} $.

% Then, Gleason's theorem states given a probability measure $\mu$
% there is a mixed state $\ket{\psi}$ such that $\mu=\mu_{\psi}$,
% i.e., the Born rule is surjective\footnote{If we extend the domain of $\mu_{\psi}$ including the mixed states.}.
% For any other formula~$\tilde{\mu}$, we can ask whether $\tilde{\mu}$
% is surjective as well.

% Obviously, we don't want arbitrarily assign a state~$\ket{\psi}\in\Hilb\backslash\left\{ 0\right\} $
% with a probability measure $\tilde{\mu}_{\psi}$, for example, assigning
% every state to the same probability measure. We want $\tilde{\mu}_{\psi}$
% satisfying the following properties with some physical meaning:
% \begin{itemize}
% \item $\ip{\psi}{\phi}=0\Leftrightarrow\tilde{\mu}_{\psi}\left(\proj{\phi}\right)=\tilde{0}$,
% where $\tilde{0}$ is $0$ for $\left[0,1\right]$ and $\tilde{0}$
% is impossible for $\mathscr{L}_{2}=\left\{ \imposs,\poss\right\} $. 
% \item $\tilde{\mu}_{\psi}\left(\proj{\phi}\right)=\tilde{\mu}_{\mathbf{U}\ket{\psi}}\left(\mathbf{U}\proj{\phi}\mathbf{U}^{\dagger}\right)\textrm{ ,}$where
% $\ket{\psi},\ket{\phi}$ are states and $\mathbf{U}$ is any unitary
% map, i.e., $\mathbf{U}^{\dagger}\mathbf{U}=\mathbb{1}$. 
% \end{itemize}
% And the results can be summarized in the following table:\\
% \center{ %
% \begin{tabular}{>{\raggedright}m{0.2\columnwidth}>{\raggedright}m{0.2\columnwidth}>{\raggedright}m{0.2\columnwidth}>{\raggedright}m{0.2\columnwidth}}
% \hline 
% State space $\Hilb$  & Probability values  & Is there a $\tilde{\mu}$ satisfying the given conditions?  & Is the $\tilde{\mu}$ surjective?\tabularnewline
% \hline 
% \hline 
% $\C^{d}$ for $d\ge3$  & $\left[0,1\right]$  & Yes  & Yes\tabularnewline
% \hline 
% $\C^{d}$  & $\mathscr{L}_{2}$  & Yes  & No\tabularnewline
% \hline 
% $\ffzd{p^{2}}$for $d\ge3$ except $d=p=3$  & $\left[0,1\right]$  & No  & \tabularnewline
% \hline 
% $\ffzd{p^{2}}$  & $\mathscr{L}_{2}$  & Yes & No\tabularnewline
% \hline 
% \end{tabular}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{All Continuous or All Discrete}

Before we turn to the main part of the paper, we quickly dismiss the
possibility of having one but not the other of the discrete
variations. Specifically, it is impossible to maintain the Hilbert
space and have a finite set-valued probability measure and it is also
impossible to have a vector space constructed over a finite field with
a real-valued probability measure. 

%%%
\subsection{Hilbert Space with Finite Set-Valued Probability Measure}

However, there is a $\mathscr{L}_{2}$-valued probability measure
\[
\hat{\mu}_{1}\left(E\right)=\begin{cases}
\imposs & \textrm{, if }E=\proj{+};\\
\bar{\mu}(E) & \textrm{, otherwise.}
\end{cases}
\]
such that $\hat{\mu}_{1}\ne\bar{\mu}_{\psi}$ for all mixed state
$\ket{\psi}$.

%%%
\subsection{Discrete Vector Space with Real-Valued Probability Measure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{discreteGBKS}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Probability space (restricted to finite sample spaces)

* Sample space Ω (arbitrary finite non-empty set)
* Set of events F: pick 2^Ω
* Probability measure (real-valued): P : F → [0,1] such that:
  * For any collection of pairwise disjoint Aᵢ ∈ F, we have P ( ∪ᵢ Aᵢ) = ∑ᵢ P(Aᵢ) 
  * P(Ω) = 1


Set-value probability measures. Change the last bullet to:
* P : F → 2^(ℝⁿ) such that: ...

%%%%%
\subsection{Sample Space $\Omega$} 

In this paper, we will only consider \textbf{finite} sample spaces. We
therefore define a sample space $\Omega$ as a non-empty finite set.

\begin{example}[A Classical Sample Space.]
Consider an experiment that tosses three coins. A possible outcome of
the experiment is $HHT$ which means that the first and second coins
landed with ``heads'' as the face-up side and that the third coin
landed with ``tails'' as the face-up side. There are clearly a total
of eight possible outcomes, and this collection constitutes the sample
space:
\[
\Omega_C = \{ HHH, HHT, HTH, HTT, THH, THT, TTH, TTT \}
\]
\end{example}

\begin{example}[A Quantum Sample Space.]
Consider a quantum system composed of three electrons. By the
postulates of quantum mechanics, an experiment designed to measure
whether the spin of each electron along the $x$ axis is left ($L$) or
right ($R$) can only result in one of eight outcomes:
\[
\Omega_H = \{ LLL, LLR, LRL, LRR, RLL, RLR, RRL, RRR \}
\]
\end{example}

%%%%%
\subsection{Events $\mathcal{F}$} 

The space of events $\mathcal{F}$ associated with a sample space
$\Omega$ is $2^\Omega$, the powerset of $\Omega$. In other words,
every subset of $\Omega$ is a possible event.

\begin{example}[Some classical events.] 
The following are events associated with $\Omega_C$:
\begin{itemize}
\item $E_0$, exactly zero coins are $H$, is the set $\{ TTT \}$.
\item $E_1$, exactly one coin is $H$, is the set $\{ HTT, THT, TTH \}$. 
\item $E_2$, exactly two coins are $H$, is the set $\{ HHT, HTH, THH \}$.
\item $E_3$, exactly three coins are $H$, is the set $\{ HHH \}$. 
\item $E_{>0}$, at least one coin is $H$, is the set $\{ HHH, HHT, HTH, HTT, THH, THT, TTH \}$. 
\end{itemize}
As the examples illustrate, events are \emph{indirect} questions built from elementary elements of the sample space using logical connectives. Also
note that some events may be disjoint and that some events may be
expressed as combinations of other events. For example, we have
$E_{>0} = E_1 \cup E_2 \cup E_3$ and each of these four events is
disjoint from event $E_0$.
\end{example}

\begin{example}[Some quantum events.] 
The following are events associated with $\Omega_H$:
\begin{itemize}
\item $F_0$, exactly zero electrons are spinning $L$, is the set $\{ RRR \}$.
\item $F_1$, exactly one electron is spinning $L$, is the set $\{ LRR, RLR, RRL \}$. 
\item $F_2$, exactly two electrons are spinning $L$, is the set $\{ LLR, LRL, RLL \}$.
\item $F_3$, exactly three electrons are spinning $L$, is the set $\{ LLL \}$. 
\item $F_{>0}$, at least one electron is spinning $L$, is the set $\{ LLL, LLR, LRL, LRR, RLL, RLR, RRL \}$. 
\end{itemize}
As the examples illustrate, quantum events are, at first glance,
similar to classical events. There are however some subtle
differences that we point out in the next section.
\end{example}

%%%%%
\subsection{Measures $\mathbb{P}$} 

The last ingredient of a probability space is a probability measure
$\mathbb{P} : \mathcal{F} \rightarrow [0,1]$ that assigns to each
event a real number in the closed interval $[0,1]$ subject to the
following conditions:
\begin{itemize}
\item $\mathbb{P}(\Omega) = 1$, and 
\item For any collection of pairwise disjoint events $A_i$, we have 
$\mathbb{P}(\bigcup_i A_i) = \Sigma_i ~\mathbb{P}(A_i)$.
\end{itemize}

\begin{example}[Classical probability measure]
There are $2^8$ events associated with $\Omega_C$. A possible probability measure for
these events is:
\[\begin{array}{c}
\mathbb{P}(E) = \left\{ \begin{array}{ll} 
  1 & \mbox{if}~E = \Omega \\
  0 & \mbox{otherwise} 
  \end{array}\right.
\end{array}\]
\yutsung{ Actually, the above $\mathbb{P}$ is not a probability
measure because 
\[
\mathbb{P}\left(\Omega\right)=1\ne0+0=\mathbb{P}\left(E_{0}\right)+\mathbb{P}\left(E_{>0}\right)
\]
} \\
A more interesting measure is defined recursively as follows:
\renewcommand\arraystretch{1.4}
\[\begin{array}{rcl}
\mathbb{P}(\emptyset) &=& 0 \\
\mathbb{P}(\{ HHH \} \cup E) &=& \frac{1}{5} + \mathbb{P}(E) \\
\mathbb{P}(\{ HHT \} \cup E) &=& \mathbb{P}(E) \\
\mathbb{P}(\{ HTH \} \cup E) &=& \frac{3}{10} + \mathbb{P}(E) \\
\mathbb{P}(\{ HTT \} \cup E) &=& \mathbb{P}(E) \\
\mathbb{P}(\{ THH \} \cup E) &=& \frac{1}{5} + \mathbb{P}(E) \\
\mathbb{P}(\{ THT \} \cup E) &=& \mathbb{P}(E) \\
\mathbb{P}(\{ TTH \} \cup E) &=& \frac{3}{10} + \mathbb{P}(E) \\
\mathbb{P}(\{ TTT \} \cup E) &=& \mathbb{P}(E) 
\end{array}\]
\yutsung{Because $\mathbb{P}(\bigcup_{i}A_{i})=\Sigma_{i}~\mathbb{P}(A_{i})$
requires disjoint events, the above formula should write like:
\[
\begin{array}{rcl}
\mathbb{P}(\emptyset) & = & 0\\
\mathbb{P}(\{HHH\}\cup E) & = & \frac{1}{5}+\mathbb{P}(E)\textrm{, if }HHH\notin E\\
\mathbb{P}(\{HHT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }HHT\notin E\\
\mathbb{P}(\{HTH\}\cup E) & = & \frac{3}{10}+\mathbb{P}(E)\textrm{, if }HTH\notin E\\
\mathbb{P}(\{HTT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }HTT\notin E\\
\mathbb{P}(\{THH\}\cup E) & = & \frac{1}{5}+\mathbb{P}(E)\textrm{, if }THH\notin E\\
\mathbb{P}(\{THT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }THT\notin E\\
\mathbb{P}(\{TTH\}\cup E) & = & \frac{3}{10}+\mathbb{P}(E)\textrm{, if }TTH\notin E\\
\mathbb{P}(\{TTT\}\cup E) & = & \mathbb{P}(E)\textrm{, if }TTT\notin E
\end{array}
\]
Or add a sentence ``where the element in the singleton set is not
belong to $E$ for each equation.'' Or write like: 
\[
\begin{array}{rcl}
\mathbb{P}(\{HHH\}) & = & \frac{1}{5}\\
\mathbb{P}(\{HHT\}) & = & 0\\
\mathbb{P}(\{HTH\}) & = & \frac{3}{10}\\
\mathbb{P}(\{HTT\}) & = & 0\\
\mathbb{P}(\{THH\}) & = & \frac{1}{5}\\
\mathbb{P}(\{THT\}) & = & 0\\
\mathbb{P}(\{TTH\}) & = & \frac{3}{10}\\
\mathbb{P}(\{TTT\}) & = & 0\\
\mathbb{P}(E) & = & \sum_{\omega\in E}\mathbb{P}(\left\{ \omega\right\} )
\end{array}
\]
} \\
Because this is a \emph{classical} situation, the probability
assignments can be understood \emph{locally} and
\emph{non-contextually}. In other words, we can reason about each coin
separately and perform experiments on it ignoring the rest of the
context. If we were to perform such experiments we may find that for
the first coin, the probability of either outcome
$H$ or $T$ is $\frac{1}{2}$; for coin two, the probabilities are
skewed a little with the probability of outcome $H$ being
$\frac{2}{5}$ and the probability of outcome $T$ being $\frac{3}{5}$; and that
coin 3 is a fake double-headed coin where the probability of
outcome $H$ is 1 and the probability of outcome $T$ is 0. The reader
may check that these local observations are consistent with the
probability measure above. 
\end{example}

\begin{example}{[}Quantum probability measure{]} Like in the classical
case, there are $2^{8}$ events. But as Mermin explains in a simple
example~\cite{MerminPRL1990}, here is a possible probability measure:
\[
\begin{array}{rcl}
\mathbb{P}_{xxx}(\{LLL\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{LLR\}) & = & 0\\
\mathbb{P}_{xxx}(\{LRL\}) & = & 0\\
\mathbb{P}_{xxx}(\{LRR\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{RLL\}) & = & 0\\
\mathbb{P}_{xxx}(\{RLR\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{RRL\}) & = & \frac{1}{4}\\
\mathbb{P}_{xxx}(\{RRR\}) & = & 0\\
\mathbb{P}_{xxx}(E) & = & \sum_{\omega\in E}\mathbb{P}_{xxx}(\left\{ \omega\right\} )
\end{array}
\]
In contrast with the previous classical example, the event of different
electrons are not independent. More precisely, consider the event
for each electron separately:
\begin{eqnarray*}
F_{1,L} & = & \left\{ LLL,LLR,LRL,LRR\right\} \\
F_{2,L} & = & \left\{ LLL,LLR,RLL,RLR\right\} \\
F_{3,L} & = & \left\{ LLL,LRL,RLL,RRL\right\} 
\end{eqnarray*}
They are not independent means 
\[
\mathbb{P}_{xxx}(F_{1,L}\cap F_{2,L}\cap F_{3,L})=\mathbb{P}_{xxx}(\{LLL\})=\frac{1}{4}\ne\frac{1}{8}=\mathbb{P}_{xxx}(F_{1,L})\mathbb{P}_{xxx}(F_{2,L})\mathbb{P}_{xxx}(F_{3,L})\textrm{ .}
\]


Classical events may also not be independent even if they seems unrelated.
For example, events defined by the temperature is usually not independent
to ones defined by how much Coca-Cola is sold. Another example can
be formulated by tossing three coins as we discussed previously. However,
this time the coins are tossed behind a veil where someone tosses
the coins for you. Because we cannot see how she tosses the coins,
she might actually roll a four-sided tetrahedral die with $\{HHH,HTT,THT,TTH\}$
in its four faces. If $HTT$ is on the downward face, she places $H$,
$T$, and $T$ as the face-up sides of of the three coins by hand,
respectively. Then, she uncovers the veil, and claims she has tossed
the coins. If the coins are tossed in this way, the result of coin-tossing
is correlated, and we will never see $TTT$ no matter how many times
we toss these coins. 

Because we do not know how the spin of an electron is decided, Einstein,
Podolsky, and Rosen (EPR)~\cite{EPR1935} suggested the nature might
give us the probability measure~$\mathbb{P}_{xxx}$ because she rolled
a tetrahedral die or performed other classical and deterministic process
behind the veil. This claim may be convincing if $\mathbb{P}_{xxx}$
is the only probability measure we have, but will lead to a contradiction
if we consider other probability measures as well. Notice that after
the coins are placed by hand and before uncovering the veil, which
side up has already been decided although we do not know. This would
be also true for the quantum probability measure. Because the three
electrons can be spatially separated, and each electron can be measured
along the $x$ axis separately, if the nature rolled a tetrahedral
die, this die should be rolled before the electrons are separated
and measured, and she should know the result of measurement before
we measure the electrons. Let the result of the $j$-th electron measured
along the $x$ axis be $w\left(\sigma_{x}^{j}\right)$. Because 
\[
\mathbb{P}_{xxx}(\{LLR\})=\mathbb{P}_{xxx}(\{LRL\})=\mathbb{P}_{xxx}(\{RLL\})=\mathbb{P}_{xxx}(\{RRR\})=0\textrm{ ,}
\]
we have $w\left(\sigma_{x}^{1}\right)w\left(\sigma_{x}^{2}\right)w\left(\sigma_{x}^{3}\right)\in\{LLL,LRR,RLR,RRL\}$,
i.e., the number of $L$ in $w\left(\sigma_{x}^{1}\right)$, $w\left(\sigma_{x}^{2}\right)$,
and $w\left(\sigma_{x}^{3}\right)$ should be odd. 

The three electrons cannot be measured the spin only along the $x$
axis, but also along the $y$ axis with the result down ($D$) or
up ($U$). We only consider to measure even number of electrons along
the $y$ axis, and the probability measures could be defined by 
\begin{eqnarray*}
\begin{array}{rcl}
\mathbb{P}_{xyy}(\{LDD\}) & = & 0\\
\mathbb{P}_{xyy}(\{LDU\}) & = & \frac{1}{4}\\
\mathbb{P}_{xyy}(\{LUD\}) & = & \frac{1}{4}\\
\mathbb{P}_{xyy}(\{LUU\}) & = & 0\\
\mathbb{P}_{xyy}(\{RDD\}) & = & \frac{1}{4}\\
\mathbb{P}_{xyy}(\{RDU\}) & = & 0\\
\mathbb{P}_{xyy}(\{RUD\}) & = & 0\\
\mathbb{P}_{xyy}(\{RUU\}) & = & \frac{1}{4}
\end{array} & \begin{array}{rcl}
\mathbb{P}_{yxy}(\{DLD\}) & = & 0\\
\mathbb{P}_{yxy}(\{DLU\}) & = & \frac{1}{4}\\
\mathbb{P}_{yxy}(\{DRD\}) & = & \frac{1}{4}\\
\mathbb{P}_{yxy}(\{DRU\}) & = & 0\\
\mathbb{P}_{yxy}(\{ULD\}) & = & \frac{1}{4}\\
\mathbb{P}_{yxy}(\{ULU\}) & = & 0\\
\mathbb{P}_{yxy}(\{URD\}) & = & 0\\
\mathbb{P}_{yxy}(\{URU\}) & = & \frac{1}{4}
\end{array} & \begin{array}{rcl}
\mathbb{P}_{yyx}(\{DDL\}) & = & 0\\
\mathbb{P}_{yyx}(\{DDR\}) & = & \frac{1}{4}\\
\mathbb{P}_{yyx}(\{DUL\}) & = & \frac{1}{4}\\
\mathbb{P}_{yyx}(\{DUR\}) & = & 0\\
\mathbb{P}_{yyx}(\{UDL\}) & = & \frac{1}{4}\\
\mathbb{P}_{yyx}(\{UDR\}) & = & 0\\
\mathbb{P}_{yyx}(\{UUL\}) & = & 0\\
\mathbb{P}_{yyx}(\{UUR\}) & = & \frac{1}{4}
\end{array}
\end{eqnarray*}
with $\mathbb{P}_{ijk}(E)=\sum_{\omega\in E}\mathbb{P}_{ijk}(\left\{ \omega\right\} )$.
Similarly, the nature should predetermine $w\left(\sigma_{x}^{j}\right)$
and $w\left(\sigma_{y}^{j}\right)$ for them. Furthermore, because
she do not know along which axis we are going to measure, she should
predetermine the same $w\left(\sigma_{x}^{j}\right)$ and $w\left(\sigma_{y}^{j}\right)$
for all different probability measures. By the same reason as above,
the number of $L$ or $D$ in $\left\{ w\left(\sigma_{x}^{1}\right),w\left(\sigma_{y}^{2}\right),w\left(\sigma_{y}^{3}\right)\right\} $,
$\left\{ w\left(\sigma_{y}^{1}\right),w\left(\sigma_{x}^{2}\right),w\left(\sigma_{y}^{3}\right)\right\} $,
and $\left\{ w\left(\sigma_{y}^{1}\right),w\left(\sigma_{y}^{2}\right),w\left(\sigma_{x}^{3}\right)\right\} $
should be even. If we look these 9 letters carefully, we can find
that every $w\left(\sigma_{x}^{j}\right)$ appears once and every
$w\left(\sigma_{y}^{j}\right)$ appears twice. Hence, the number of
$L$ in $w\left(\sigma_{x}^{1}\right)$, $w\left(\sigma_{x}^{2}\right)$,
and $w\left(\sigma_{x}^{3}\right)$ should be even. This contradict
to the conclusion in our last paragraph. Therefore, EPR's assumption
is wrong, and it is not always true that the nature can predetermine
the measurement result before we perform the measurement. \end{example}


%%%%
\subsection{Finite Precision of Measurements}

In a laboratory setting or a computational setting, there are neither
uncountable entities nor uncomputable entities. We are thus looking at
alternative probability spaces which do not depend on the real numbers
and revisit the mysteries of quantum mechanics in that
setting. In other words, is it possible that at least part of the quantum mysteries related to probability and measurement are due to the reliance on uncomputable probability values? 

Following previous work on probability, we will replace the
closed interval $[0,1]$ by the \emph{finite set} $S = \{
\textbf{possible}, \textbf{impossible} \}$ and adapt the definition of
probability measure as follows.

A set-valued probability measure $\mathbb{P} : \mathcal{F} \rightarrow
S$ assigns to each event either the tag \textbf{possible} or the tag
\textbf{impossible} subject to the following conditions:
\begin{itemize}
\item $\mathbb{P}(\Omega) = \textbf{possible}$, and 
\item For any collection of pairwise disjoint events $A_i$, we have 
$\mathbb{P}(\bigcup_i A_i) = \textbf{possible}$ if any event $A_i$ is
\textbf{possible} and \textbf{impossible} otherwise. 
\end{itemize}

We begin by reviewing the conventional presentation of classical
probability spaces and then give an alternative formulation that is
``quantum-like'' but still classical. We conclude this section with a
definition of quantum probability spaces given as a modest
generalization of the alternative classical definition. 

%%%%%
\subsection{Conventional Classical Probability Spaces}

Textbook probability
theory~\cite{inun.425605319950101,GrahamKnuthPatashnik1994,rohatgi2011introduction}
is defined using the notions of a \emph{sample space} $\Omega$, a
space of \emph{events}~$\events$, and a \emph{probability
  measure}~$\pmeas$. In this paper, we will only consider
\emph{finite} sample spaces: we therefore define a sample space
$\Omega$ as an arbitrary non-empty finite set and the space of events
$\events$ as, $2^\Omega$, the powerset of $\Omega$. A \emph{probability
measure} is a function $\pmeas : \events \rightarrow [0,1]$ such that:
\begin{itemize}
\item $\pmeas(\Omega) = 1$, and 
\item for a collection of pairwise disjoint events $E_i$, we have
  $\pmeas(\bigcup E_i) = \sum \pmeas(E_i)$. 
\end{itemize}

\begin{example}[Two coin experiment] Consider an experiment that
  tosses two coins. We have four possible outcomes that constitute the
  sample space $\Omega = \{ HH, HT, TH, TT \}$. The event that the
  first coin is ``heads'' is $\{ HH, HT \}$; the event that the two
  coins land on opposite sides is $\{ HT, TH \}$; the event that at
  least one coin is tails is $\{ HT, TH, TT\}$. Depending on the
  assumptions regarding the coins, we can define several probability
  measures. Here is a possible one:
\[\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\pmeas(\emptyset) &=& 0 \\
\pmeas(\{ HH \}) &=& 1/3 \\
\pmeas(\{ HT \}) &=& 0 \\
\pmeas(\{ TH \}) &=& 2/3 \\
\pmeas(\{ TT \}) &=& 0 \\
\pmeas(\{  HH, HT \}) &=& 1/3 \\
\pmeas(\{  HH, TH \}) &=& 1 \\
\pmeas(\{  HH , TT \}) &=& 1/3 
\end{array} & \begin{array}{rcl}
\pmeas(\{  HT, TH \}) &=& 2/3 \\
\pmeas(\{  HT , TT \}) &=& 0 \\
\pmeas(\{  TH , TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH \}) &=& 1 \\
\pmeas(\{  HH, HT, TT \}) &=& 1/3 \\
\pmeas(\{  HH, TH, TT \}) &=& 1 \\
\pmeas(\{  HT, TH, TT \}) &=& 2/3 \\
\pmeas(\{  HH, HT, TH, TT \}) &=& 1
\end{array}
\end{array}\]
\end{example}

%%%%%
\subsection{Alternative Definition of Classical Probability Spaces}

In the conventional presentation, we have viewed the space of events
$2^\Omega$ are the powerset of $\Omega$. We can equivalently view
$2^\Omega$ as the space of functions from $\Omega$ to the set
$2 = \{0,1\}$. For example, the event $\{HT,TH\}$ is the function $e$
such that:
\[
e (HH) = 0, \quad e (HT) = 1, \quad e (TH) = 1, \quad e (TT) = 0 
\]
We will in fact do a sweeping generalization and view events as
functions from $\Omega$ to $\mathbb{C}$, the set of complex
numbers. This accommodates the previous events such as $e$ and allows
many more events such as event $e'$ below:
\[
e' (HH) = \sqrt{2} + i \sqrt{3}, \quad e' (HT) = 1, \quad e' (TH) = \pi, \quad e' (TT) = 0 
\]
The events are not going to be completely arbitrary functions,
however. We will insist on some conditions:...

This generalization

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conventional Quantum Mechanics}

Attempting to modify the probability measure to be set-valued, while keeping the rest of the mathematical framework of quantum mechanics intact leads to a contradiction. More precisely, it is not possible to maintain infinite precision probability amplitudes in the presence of set-valued probabilities without violating essential aspects of quantum theory. 

\ldots explain and give theorem

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discrete Quantum Theory}

The next question to ask is therefore whether the infinite precision of probability amplitudes is itself justified. If all measurements are finite and all probabilities are computable, then it is plausible that the internal mathematical representation of quantum states should also be based on countable computable entities. 
