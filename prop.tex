\documentclass{article}
\usepackage[ backend=biber]{biblatex}
\addbibresource{proposal/prop.bib}
\ExecuteBibliographyOptions{sorting=none,maxbibnames=5,doi=false,isbn=false,url=false}
\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{bbold}
\usepackage{wesa}
\usepackage{graphicx}
\usepackage{verbatim}

\theoremstyle{remark}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{thm}{Theorem}

\newcommand{\Hilb}{\mathcal{H}}
\newcommand{\events}{\ensuremath{\mathcal{E}}}
\newcommand{\qevents}{\ensuremath{\mathcal{E}}}
\newcommand{\pmeas}{\ensuremath{\mu}}
\newcommand{\imposs}{{\mbox{\wesa{impossible}}}}
\newcommand{\likely}{{\mbox{\wesa{likely}}}}
\newcommand{\unlikely}{{\mbox{\wesa{unlikely}}}}
\newcommand{\necess}{{\mbox{\wesa{certain}}}}
\newcommand{\unknown}{{\mbox{\wesa{unknown}}}}
\newcommand{\ket}[1]{{\left\vert{#1}\right\rangle}}
\newcommand{\op}[2]{\ensuremath{\left\vert{#1}\middle\rangle\middle\langle{#2}\right\vert}}
\newcommand{\proj}[1]{\op{#1}{#1}}
\newcommand{\ps}{\texttt{+}}
\newcommand{\ms}{\texttt{-}}
\newcommand{\ip}[2]{\ensuremath{\left\langle{#1}\middle\vert{#2}\right\rangle}}
\newcommand{\Tr}{\mathop{\mathrm{Tr}}\nolimits}
\newcommand{\rme}{\mathrm{e}}
\newcommand{\rmi}{\mathrm{i}}

\begin{document}
\title{Measurement and Probability in Fuzzy Quantum Theories}
\date{\today}
\maketitle 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} 

This is a \emph{theoretical} investigation of \emph{experimental}
physics using \emph{computational} methods. All experiments and computations
are processes bounded in space, time, energy, and other resources~\cite{Jaeger2007,Li2009}.
Yet, for centuries, the mathematical formalization of such processes
has been founded on the infinitely precise real or complex numbers.
Our purpose here is exploit the consequences of replacing infinitely-specified
quantum probabilities by finite number of intervals used in interval-valued
probability measures; in particular, we show that a quantum interval-valued
probability measure may not be induced by a infinitely-precise state,
but it might be more and more likely to be identified to a particular
state when the measurement resources increase.

Indeed, almost every description of quantum mechanics, quantum computation,
or quantum experiments refers to entities such as $\rme$, $\pi$,
$\sqrt{2}$, etc. From a computational perspective, such numbers do
not exist in their entirety ``for free~\cite{Kent1999,CliftonKent2000}.''
For example, the state of the art algorithms for computing the $n$th
binary digit of~$\pi$ require on the order of $O\left(n\log^{O\left(1\right)}\left(n\right)\right)$
operations~\cite{journals/moc/BaileyBP97}. In other words, simply
referring to the $n$th digit of $\pi$ requires more and more resources
as $n$ gets larger. Taking such resource bounds into consideration
is what founded computer science as a discipline and is crucial for
understanding the very nature of computation and, following Feynman~\cite{Feynman1982Simulating},
Landauer~\cite{Landauer1996188}, and others, for understanding the
very nature of physical processes.

We propose to revisit quantum mechanics, quantum information, and
quantum computation from this resource-aware perspective. Our initial
results in that domain showed how subtle the issues can
be~\cite{usat,geometry2013,DQT2014}: a straightforward replacement of
the complex numbers by a finite field yields a variant of quantum
mechanics in which computationally hard problems like UNIQUE-SAT
(which decides whether a given Boolean formula is unsatisfiable or has
exactly one satisfying assignment) can be deterministically solved in
constant time. To eliminate such unrealistic theories requires
delicate analysis of the structure of the Hilbert space, the process
of observation, and the notion of probability teasing apart their
reliance on the infinitely precise real
numbers~\cite{geometry2013,DQT2014}. 

In this proposal, our aim is to
shift focus from the infinitely-specified but not directly observable
quantum states, to observable measurable properties of quantum systems
and their probabilities. Furthermore, we insist that our theories of
measurement and probability only refer to finitely communicable
evidence within feasible computational bounds. It follows that states,
observations, and probabilities all become ``fuzzy'', i.e., specified
by intervals of confidence that can only increase in precision if the
available resources increase proportionally. Our notion of ``fuzzy
quantum mechanics'' is related to existing
work~\cite{GranikCaulfield1996,Pykacz2013,SNL2009,Gudder2005,aerts1993physical}
but, as will be explained in more detail, is distinguished by its
unique computational character.

We will begin by reviewing existing work that recasts classical
probability spaces in a resource-aware setting and move to our
proposal which, briefly speaking, aims at recasting quantum
probability and hence quantum measurement to a corresponding
resource-aware setting.

In particular, the objectives to be achieved include:
\begin{itemize}
\item Develop a measurement framework based on quantum interval-valued
  probabilities measures.
\item Assess the validity of fundamental theorems of quantum
  mechanics, such as Gleason, Bell, and Kochen-Specker, in a quantum
  formulation stripped away of infinite resources. We will aim to
  provide a definite answer to the Meyer-Mermin
  debate~\cite{PhysRevLett.83.3751, Mermin1999, BarrettKent2004} on
  the impact of finite precision measurements on the relevance of the
  Kochen-Specker
  theorem~\cite{kochenspecker1967,Redhead1987-REDINA,peres1995quantum,Jaeger2007}.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classical Probability}

A \emph{probability space} specifies the necessary conditions for
reasoning coherently about collections of uncertain
events~\cite{Kolmogorov1950,Shafer1976,Griffiths2003,Swart2013}.  We
review the conventional presentation of probability spaces and then
discuss the computational resources needed to estimate probabilities.

%%%
\subsection{Classical Probability Spaces}

The conventional definition of a probability space builds upon the
field of real numbers. In more detail, a probability space consists of
a \emph{sample space} $\Omega$, a space of \emph{events}~$\events$,
and a \emph{probability measure}~$\pmeas$ mapping events in $\events$
to the real interval $[0,1]$. We will only consider \emph{finite} sets
of events and restrict our attention to non-empty finite sets $\Omega$
as the sample space. The space of events $\events$ includes every
possible subset of $\Omega$: it is the
powerset~$2^{\Omega}=\left\{ E ~\middle|~ E\subseteq\Omega\right\}
$.
For future reference, we emphasize that events are the primary notion
of interest and that the sample space is a convenient artifact that
allows us to treat events as sets obeying the laws of Boolean
algebra~\cite{Boole1948,Redhead1987-REDINA,Griffiths2003}.

\begin{definition}[Probability Measure]\label{def:ClassicalProbabilitySpace}
  Given the set of events $\events$, a \emph{probability measure} is a
  function $\pmeas:\events\rightarrow[0,1]$ such that:
\begin{itemize}
\item $\pmeas(\emptyset)=0$,
\item $\pmeas(\Omega)=1$, 
\item for every event $E$,
  $\pmeas\left(\Omega\backslash E\right)=1-\pmeas\left(E\right)$ where
  $\Omega\backslash E$ is the complement event of $E$, and
\item for every collection $\left\{ E_{i}\right\} _{i=1}^{N}$ of
  pairwise disjoint events,
  $\pmeas\left(\bigcup_{i=1}^{N}E_{i}\right)=\sum_{i=1}^{N}\pmeas(E_{i})$.
\end{itemize}
\end{definition}
\noindent There is some redundancy in the definition that will be useful when
moving to quantum probability spaces. 

\begin{example}[Two-coins experiment]\label{ex1} Consider an
  experiment that tosses two coins. We have four possible outcomes
  that constitute the sample space $\Omega=\{HH,HT,TH,TT\}$. There are
  16 total events including the event $\{HH,HT\}$ that the first coin
  lands heads up, the event $\{HT,TH\}$ that the two coins land on
  opposite sides, and the event $\{HT,TH,TT\}$ that at least one coin
  lands tails up. Here is a possible probability measure for these
  events:
\[
\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\pmeas(\emptyset) & = & 0\\
\pmeas(\{HH\}) & = & 1/3\\
\pmeas(\{HT\}) & = & 0\\
\pmeas(\{TH\}) & = & 2/3\\
\pmeas(\{TT\}) & = & 0\\
\pmeas(\{HH,HT\}) & = & 1/3\\
\pmeas(\{HH,TH\}) & = & 1\\
\pmeas(\{HH,TT\}) & = & 1/3
\end{array} & \begin{array}{rcl}
\pmeas(\{HT,TH\}) & = & 2/3\\
\pmeas(\{HT,TT\}) & = & 0\\
\pmeas(\{TH,TT\}) & = & 2/3\\
\pmeas(\{HH,HT,TH\}) & = & 1\\
\pmeas(\{HH,HT,TT\}) & = & 1/3\\
\pmeas(\{HH,TH,TT\}) & = & 1\\
\pmeas(\{HT,TH,TT\}) & = & 2/3\\
\pmeas(\{HH,HT,TH,TT\}) & = & 1
\end{array}\end{array}
\]
\end{example}

\noindent It is useful to think that this probability measure is
completely determined by the ``reality'' of the two coins in question
and their characteristics, in the sense that each pair of coins
induces a measure, and each measure must correspond to some pair of
coins. The measure above would be induced by two particular coins such
that the first coin is twice as likely to land tails up than heads up
and the second coin is double-headed. In a strict computational
or experimental setting, one should question the reliance of the
definition of probability space on the uncountable and
uncomputable real
interval~$[0,1]$~\cite{Turing_1937,Ziegler2007,weihrauch2012computable}.
This interval includes numbers like
$0.h_{1}h_{2}h_{3}\ldots$ where $h_{i}$ is 1 or 0 depending on whether
Turing machine $\mathit{TM}_{i}$ halts or not. Such numbers cannot be
computed. This interval also includes numbers like $\frac{\pi}{4}$
which can only be computed with increasingly large resources as the
precision increases. Therefore, in a resource-aware computational or
experimental setting, it is more appropriate to consider probability
measures that map events to a set of elements computable with a fixed
set of resources. We expand on this observation in the next section
and then recall its formalization using interval-valued probability
measures~\cite{Weichselberger2000,JamisonLodwick2004}.

%%%%%
\subsection{Measuring Probabilities: Buffon's Needle Problem\label{subsec:Measuring-Probabilities:-Buffon}}

In the previous example, we assumed the probability~$\pmeas(E)$ of
each event~$E$ is known a priori. In reality, although each event is
assumed to have a probability, the exact value of $\pmeas(E)$ may not
be known. According to the \emph{frequency interpretation of
  probability} (which we will revisit when moving to the quantum
case)~\cite{Venn1876,Hajek2012}, 
to determine the probability of an event, we run $M$
independent trials which gives us an approximation of the (assumed)
``true'' or ``real'' probability. Let $x_{i}$ be 1 or 0 depending on
whether the event~$E$ occurs in the $i$-th trial or not, then
$\pmeas(E)$ could be approximated to given accuracy~$\epsilon>0$ by
the relative frequency~$\frac{1}{M}\sum_{i=1}^{M}x_{i}$ with the
probability converging to one as $M$ goes to infinity, i.e.,
\[
\forall\epsilon>0,\lim_{M\rightarrow\infty}\pmeas\left(\left|\pmeas(E)-\frac{1}{M}\sum_{i=1}^{M} x_{i}\right|<\epsilon\right)=1\textrm{ .}
\]
This fact is called the law of large numbers~\cite{Bernoulli2006,Kolmogorov1950,Uspensky1937,Shafer1976,544199}.

Let's look at a concrete example. Suppose we drop a needle of length
$\ell$ onto a floor made of equally spaced parallel lines a distance
$h$ apart, where $\ell<h$. It is a known fact that the probability of
the needle crossing a line is
$\frac{2\ell}{\pi
  h}$~\cite{Buffon1777,DeMorgan1872,Hall1873,Uspensky1937}.
Consider an experimental setup consisting of a collection of $M$
identical needles of length $\ell$. We throw the $M$ needles one
needle at a time, and observe the number $M_c$ of needles that cross a
line, thus estimating the probability of a needle crossing a line to
be $\frac{M_c}{M}$. In an actual experiment with $500$ needles and the
ratio $\frac{\ell}{h}=0.75$~\cite{Hall1873}, it was found that $236$
crossed a line so the relative frequency is $0.472$ whereas the
idealized mathematical probability is $0.4774\ldots$.  In a larger
experiment with $5000$ needles and the ratio
$\frac{\ell}{h}=0.8$~\cite{Uspensky1937}, the relative frequency was
calculated to be $0.5064$ whereas the idealized mathematical
probability is $0.5092\ldots$. We see that the observed probability
approaches $\frac{2\ell}{\pi h}$ but only if \emph{larger and larger
  resources} are expended. These resource considerations suggest that
it is possible to replace the real interval $[0,1]$ with rational
numbers up to a certain precision related to the particular experiment
in question. There is clearly a connection between the number of
needles and the achievable precision: in the hypothetical experiment
with 3 needles, it is not sensible to retain 100 digits in the
expansion of $\frac{2\ell}{\pi h}$.

There is another more subtle assumption of unbounded computational
power in the experiment. We are assuming that we can always determine
with certainty whether a needle is crossing a line. But ``lines'' on
the the floor have thickness, their distance apart is not exactly $h$,
and the needles' lengths are not all absolutely equal to $\ell$.
These perturbations make the events ``fuzzy.'' Thus, in an experiment
with limited resources, it is not possible to talk about the idealized
event that exactly $M_c$ needles cross lines as this would require the
most expensive needles built to the most precise accuracy, laser
precision for drawing lines on the floor, and the most powerful
microscopes to determine if a needle does cross a line. Instead we
might talk about the event that $M_c-\delta$ needles evidently cross
lines and $M_c+\delta'$ needles plausibly cross lines where $\delta$ and
$\delta'$ are resource-dependent approximations. This fuzzy notion of
events leads to probabilities being only calculable within intervals
of confidence reflecting the certainty of events and their
plausibility. This is indeed consistent with published experiments: in
an experiment with $3204$ needles and the ratio
$\frac{\ell}{h}=0.6$~\cite{DeMorgan1872}, $1213$ needles clearly
crossed a line and $11$ needles were close enough to plausibly be
considered as crossing the line: we would express the probability in
this case as the interval
$\left[\frac{1213}{3204},\frac{1224}{3204}\right]$ expressing that we
are certain that the event has probability at least
$\frac{1213}{3204}$ but it is possible that it would have probability
$\frac{1224}{3204}$.

%%%%%
\subsection{Classical Interval-Valued Probability Measures}

As motivated above, an event $E_{1}$ may have an interval of
probability $[l_{1},r_{1}]$. Assume that another disjoint event
$E_{2}$ has an interval of probability $[l_{2},r_{2}]$, what is the
interval of probability for the event $E_{1}\cup E_{2}$? The answer is
somewhat subtle: although it is possible to use the sum of the
intervals $[l_{1}+l_{2},r_{1}+r_{2}]$ as the combined probability, one
can find a much tighter interval if information \emph{against} the
event (i.e., information about the complement event) is also taken
into consideration. Formally, for a general event $E$ with probability
$[l,r]$, the evidence that contradicts $E$ is evidence supporting the
complement of $E$.  The complement of $E$ must therefore have
probability $\left[1-r,1-l\right]$ which we abbreviate
$\left[1,1\right]-\left[l,r\right]$.  Given a sample space~$\Omega$
and its set of events~$\events$, a
function~$\bar{\mu}:\events\rightarrow[0,1]$ is a classical
interval-valued probability measure if and only if $\bar{\mu}$
satisfies the following conditions~\cite{JamisonLodwick2004} where the
last line uses $\subseteq$ to allow for tighter intervals that exploit
the complement event:
\begin{itemize}
\item $\bar{\mu}(\emptyset)=[0,0]$.
\item $\bar{\mu}(\Omega)=[1,1]$. 
\item For any event $E$,
  $\bar{\mu}\left(\Omega\backslash E\right)=\left[1,1\right]-\bar{\mu}\left(E\right)$
\item For a collection $\left\{ E_{i}\right\} _{i=1}^{M}$ of pairwise
  disjoint events, we have
  $\bar{\mu}\left(\bigcup_{i=1}^{M}E_{i}\right)\subseteq\sum_{i=1}^{M}\bar{\mu}\left(E_{i}\right)$.
\end{itemize}

\begin{example}[Two-coin experiment with interval probability]
\label{ex3} We split the unit interval $[0,1]$ in the following
four closed sub-intervals: $[0,0]$ which we call \imposs, $[0,\frac{1}{2}]$
which we call \unlikely, $[\frac{1}{2},1]$ which we call \likely,
and $[1,1]$ which we call \necess. Using these new values, we can
modify the probability measure of Ex.~\ref{ex1} by mapping each
numeric value to the smallest sub-interval containing it to get the
following: 
\[
\begin{array}{c@{\qquad\qquad}c}
\begin{array}{rcl}
\bar{\mu}(\emptyset) & = & \imposs\\
\bar{\mu}(\{HH\}) & = & \unlikely\\
\bar{\mu}(\{HT\}) & = & \imposs\\
\bar{\mu}(\{TH\}) & = & \likely\\
\bar{\mu}(\{TT\}) & = & \imposs\\
\bar{\mu}(\{HH,HT\}) & = & \unlikely\\
\bar{\mu}(\{HH,TH\}) & = & \necess\\
\bar{\mu}(\{HH,TT\}) & = & \unlikely
\end{array} & \begin{array}{rcl}
\bar{\mu}(\{HT,TH\}) & = & \likely\\
\bar{\mu}(\{HT,TT\}) & = & \imposs\\
\bar{\mu}(\{TH,TT\}) & = & \likely\\
\bar{\mu}(\{HH,HT,TH\}) & = & \necess\\
\bar{\mu}(\{HH,HT,TT\}) & = & \unlikely\\
\bar{\mu}(\{HH,TH,TT\}) & = & \necess\\
\bar{\mu}(\{HT,TH,TT\}) & = & \likely\\
\bar{\mu}(\{HH,HT,TH,TT\}) & = & \necess
\end{array}\end{array}
\]
Despite the absence of infinitely precise numeric information, the
probability measure is quite informative: it reveals that the second
coin is double-headed and that the first coin is biased. To understand
the $\subseteq$-condition, consider the following calculation:
\begin{eqnarray*}
\bar{\mu}(\{HH\})+\bar{\mu}(\{HT\})+\bar{\mu}(\{TH\})+\bar{\mu}(\{TT\})
&=& \imposs+\unlikely+\imposs+\likely\\
&=& \left[0,0\right]+\left[0,\frac{1}{2}\right]+\left[0,0\right]+\left[\frac{1}{2},1\right]\\
&=& \left[\frac{1}{2},\frac{3}{2}\right]
\end{eqnarray*}
If we were to equate $\bar{\mu}(\Omega)$ with the sum of the individual
probabilities, we would get that $\bar{\mu}(\Omega)=\left[\frac{1}{2},\frac{3}{2}\right]$.
However, using the fact that $\bar{\mu}(\emptyset)=\imposs$, we have
$\bar{\mu}\left(\Omega\right)=1-\bar{\mu}\left(\emptyset\right)=\necess=[1,1]$.
This interval is tighter and a better estimate for the probability
of the event $\Omega$, and of course it is contained in $[\frac{1}{2},\frac{3}{2}]$.
However it is only possible to exploit the information about the complement
when all four events are combined. Thus the $\subseteq$-condition
allows us to get an estimate for the combined event from each of its
constituents and then gather more evidence knowing the aggregate
event.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quantum Probability}
 
The mathematical framework of classical probability above assumes that
there exists a predetermined set of events that are independent of the
particular experiment --- classical physics is
non-contextual~\cite{kochenspecker1967,Redhead1987-REDINA,peres1995quantum,Jaeger2007}. 
However, even in classical situations, the structure
of the event space is often only partially known and the precise
dependence of two events on each other cannot, a priori, be determined
with certainty. In the quantum framework, this partial knowledge is
compounded by the fact that there exist non-commuting events which
cannot happen simultaneously. To accommodate these more complex
situations, conventional approaches to quantum probability abandon the
sample space~$\Omega$ and reason directly about events which are
generalized from plain sets to projection operators. A quantum
probability space therefore consists of just two components: a set of
events $\qevents$ often formalized as projection operators and a
probability measure $\mu:\qevents\rightarrow[0,1]$ formalized using
the Born rule~\cite{Born1983,Mermin2007,Jaeger2007}.

%%%%%
\subsection{Quantum Events}

\begin{definition}[Projection Operators; Orthogonality~\cite{10.2307/2308516,Redhead1987-REDINA,peres1995quantum,Griffiths2003,Swart2013}]
  \label{def:Projection} Given a Hilbert space $\Hilb$, an event (an
  experimental proposition~\cite{BirkhoffVonNeumann1936}, a
  question~\cite{10.2307/2308516,Abramsky2012},
  or an elementary quantum test~\cite{peres1995quantum}) is represented
  as a (self-adjoint or orthogonal~\cite {Griffiths2003,Maassen2010})
  projection operator $P:\Hilb\rightarrow\Hilb$ onto a linear subspace
  of $\Hilb$. The following define projections and list some of their properties:
\begin{itemize}
\item $\mathbb{0}$ is a projection. 
\item For any pure state~$\ket{\psi}$, $\proj{\psi}$ is a projection
operator. 
\item Projection operators $P_{0}$ and $P_{1}$ are \emph{orthogonal}
  if $P_{0}P_{1}=P_{1}P_{0}=\mathbb{0}$. The sum of two projection
  operators~$P_{0}+P_{1}$ is also a projection operator if and only if
  they are orthogonal.
\item Conversely, every projection~$P$ can be expressed as
  $\sum_{j=1}^{N}\proj{\psi_{j}}$, where $P$ actually projects onto
  the linear subspace with orthonormal
  basis~$\left\{ \ket{\psi_{j}}\right\} _{j=1}^{N}$.
\item A set of projections $\left\{ P_{i}\right\} _{i=1}^{N}$ is
  called an \emph{ideal measurement} if it is a partition of the
  identity, i.e., $\sum_{i=1}^{N}P_{i}=\mathbb{1}$~\cite{Swart2013}.
  In this case, projections $\left\{ P_{i}\right\} _{i=1}^{N}$ must
  be mutually orthogonal~\cite{Griffiths2003,Halmos1957}, and $N$ must be less
  or equal to the dimension of the Hilbert space.
\item If $P$ is a projection operator, then $\mathbb{1}-P$ is also a
  projection operator, called its \emph{complement}. It is orthogonal to
  $P$, and corresponds to the complement event~$\Omega\backslash E$ in
  classical probability~\cite{Griffiths2003}.
\item Projection operators $P_{0}$ and $P_{1}$ \emph{commute} if $P_{0}P_{1}=P_{1}P_{0}$.
The product of two projection operators~$P_{0}P_{1}$ is also a projection
operator if and only if they commute. This corresponds to the classical
intersection between events~\cite{peres1995quantum,Griffiths2003}. 
\item For two commuting projection operators $P_{0}$ and $P_{1}$,
  their \emph{disjunction}~$P_{0}\vee P_{1}$ is defined to be
  $P_{0}+P_{1}-P_{0}P_{1}$~\cite{Griffiths2003}.
\end{itemize}
\end{definition}

\begin{example}[One-qubit quantum probability space] Consider a
  one-qubit Hilbert space with each event interpreted as a possible
  post-measurement state~\cite{peres1995quantum,Mermin2007,Jaeger2007}. 
  For example, the event $\proj{0}$ indicates
  that the post-measurement state will be $\ket{0}$; the probability
  of such an event depends on the current state; the event $\proj{1}$
  indicates that the post-measurement state will be $\ket{1}$; the
  event $\proj{\ps}$ where
  $\ket{\ps}=\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$ indicates that the
  post-measurement state will be $\ket{\ps}$; the event
  $\mathbb{1}=\proj{0}+\proj{1}$ indicates that the post-measurement
  state will be a linear combination of $\ket{0}$ and $\ket{1}$ and is
  clearly certain; finally the empty event $\mathbb{0}$ states that
  the post-measurement state will be the empty state and is
  impossible. As in the classical case, a probability measure is a
  function that maps events to $[0,1]$. Here is a partial
  specification of a possible probability measure that would be
  induced by a system whose current state is $\ket{0}$,
  $\mu\left(\mathbb{0}\right)=0$, $\mu\left(\mathbb{1}\right)=1$,
  $\mu\left(\proj{0}\right)=1$, $\mu\left(\proj{1}\right)=0$,
  $\mu\left(\proj{\ps}\right)=1/2$, \ldots. Note that, similarly to
  the classical case, the probability of $\mathbb{1}$ is 1 and the
  probability of collections of orthogonal events (e.g.,
  $\proj{0}+\proj{1}$) is the sum of the individual probabilities.  A
  collection of non-orthogonal events (e.g., $\proj{0}$ and
  $\proj{\ps}$) is however not even a valid event. In the classical
  example, we argued that each probability measure is uniquely
  determined by two actual coins. A similar (but much more subtle)
  argument is valid also in the quantum case. By postulates of quantum
  mechanics and Gleason's theorem, it turns out that for large enough
  quantum systems, each probability measure is uniquely determined by
  an actual quantum state as discussed next.
\end{example}

%%%%%
\subsection{Quantum Probability Measures}

Given our setup, the definition of a quantum probability measure is a
small variation on the classical definition. 

\begin{definition}[Quantum Probability Measure~\cite{10.2307/2308516,gleason1957,Redhead1987-REDINA,Maassen2010}]\label{def:QuantumProbabilitySpace}
Given a Hilbert space $\Hilb$ with its set of events~$\events$,
a \emph{quantum probability measure} is a function~$\mu:\events\rightarrow[0,1]$
such that: 
\begin{itemize}
\item $\mu(\mathbb{0})=0$. 
\item $\mu(\mathbb{1})=1$. 
\item For any projection $P$, $\mu\left(\mathbb{1}-P\right)=1-\mu\left(P\right)$.
\item For a set of mutually orthogonal projections $\left\{ P_{i}\right\} _{i=1}^{N}$,
we have $\mu\left(\sum_{i=1}^{N}P_{i}\right)=\sum_{i=1}^{N}\mu\left(P_{i}\right)$.
\end{itemize}
\end{definition}

\noindent A quantum probability measure can be easily constructed if
one knows the current state of the quantum system by using the Born
rule.  Specifically, for each
pure normalized quantum state $\ket{\phi}$, the Born rule induces a
probability measure $\mu_{\phi}^{B}$ defined as
$\mu_{\phi}^{B}(P)=\ip{\phi}{P\phi}$. The situation generalizes to
mixed states $\rho = \sum_{j=1}^{N}q_{j}\proj{\phi_{j}}$, where
$\sum_{j=1}^{N}q_{j}=1$ in which case the generalized Born rule
induces a probability measure $\mu_{\rho}^{B}$ defined
as
$\mu_{\rho}^{B}\left(P\right) = \Tr\left(\rho P\right) =
\sum_{j=1}^{N}
q_{j}\mu_{\phi_{j}}^{B}\left(P\right)$~\cite{peres1995quantum,544199,Jaeger2007}.
Conversely every probability measure must be of this form.

\begin{thm}[Gleason's
  theorem~\cite{gleason1957,Redhead1987-REDINA,peres1995quantum}]\label{cor:Gleason's}In
a Hilbert space $\Hilb$ of dimension $d\geq3$, given a quantum probability
measure~$\mu:\events\rightarrow[0,1]$, there exists a unique mixed
state~$\rho$ such that $\mu=\mu_{\rho}^{B}$.
\end{thm}

%%%%%
\subsection{Measuring Quantum Probabilities}

Similarly to the classical case, it is possible to estimate quantum
probabilities by utilizing the frequentist approach of the previous
section, assuming identical measurements conditions in each repeated
experiment~\cite{peres1995quantum}. 
For instance, if one wants to determine the probability
that the spin of a given silver atom is $+\hbar/2$, a Stern-Gerlach
apparatus is built where ideally an inhomogeneous magnetic field is
generated along, let's say, the quantization axis $z$. One then
produces a collimated beam of identically prepared (neutral) silver
atoms that is directed between the poles of the magnet where a
predetermined field-gradient along the $z$ direction has been
established. Under appropriate experimental conditions we will observe
that the beam, after traversing the magnetic-field region, will be
deflected towards two regions identified by distinguished spots on a
detector situated behind the
apparatus~\cite{Stern1988,peres1995quantum,544199,Griffiths2003}.
Each of the two discrete values is associated to either $+\hbar/2$ or
$-\hbar/2$, commonly called ``spin up'' and ``spin down'',
respectively. By ``counting'' the number of atoms that are deflected
in the ``spin up'' region one can, in principle, estimate the
probability that the prepared state of the silver atom state has spin
$+\hbar/2$. Notice that a real experiment does not necessarily
represent an ``ideal measurement''. For example, not all silver atoms
will be identically prepared, or the field-gradient could not be large
enough to distinguish between the spin up and down situations simply
producing a large single blot. In other words, the closer we get to an
ideal measurement the better we determine those probabilities at the
cost of significantly increasing the number of resources. It is not
very well appreciated in the literature that Bohr attempted to argue
against the measurability of the spin of a free electron. Essentially,
Bohr argued (and Mott later on justified his assertion by an elegant
use of uncertainty relations~\cite{10.2307/j.ctt7ztxn5.15}) that a
Stern-Gerlach experiment could not succeed in establishing the spin of
an unbound electron because the Lorentz force would blur the detected
pattern. This example illustrates the case of a fundamental physical
limitation that not even infinite resources could mitigate.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quantum Interval-valued Probability Measures}
 
This is the most developed part of our current investigation and is
presented in greater detail than the other proposed activities. It
relies on current unpublished results. As argued in the previous
sections, given fixed finite resources, it is only possible to
estimate the quantum probabilities within an interval of
confidence. It is therefore natural to propose the notion of a
``quantum interval-valued probability measure'' that combines the
definitions of conventional quantum probability measures with
classical interval-probabilities.

\begin{definition}[Quantum Interval-valued Probability Measure]\label{def:QuantumInterval-valuedProbability}
  Given a Hilbert space $\Hilb$ with quantum events
  (projections)~$\events$, and a collection of
  intervals~$\mathscr{I}$, a \emph{quantum
    $\mathscr{I}$-interval-valued probability measure} is a
  function~$\bar{\mu}:\events\rightarrow\mathscr{I}$ such that:
\begin{itemize}
\item $\bar{\mu}(\mathbb{0})=\left[0,0\right]$. 
\item $\bar{\mu}(\mathbb{1})=\left[1,1\right]$. 
\item For any projection $P$,
  $\bar{\mu}\left(\mathbb{1}-P\right)=\left[1,1\right]-\bar{\mu}\left(P\right)$.
\item For a set of mutually orthogonal projections
  $\left\{ P_{i}\right\} _{i=1}^{N}$, we have
  $\bar{\mu}\left(\sum_{i=1}^{N}
    P_{i}\right)\subseteq\sum_{i=1}^{N}\bar{\mu}\left(P_{i}\right)$.
\end{itemize}
\end{definition}

\noindent It is easy to establish that quantum interval-valued
probability measures generalize conventional quantum probability
measures. In particular, any quantum probability measure can be recast
as an interval-valued measure using the three intervals
$\left[0,0\right]$, $\left[1,1\right]$ and \emph{$\left[0,1\right]$},
where $\left[0,0\right]$ and $\left[1,1\right]$ are called \imposs~and
\necess~as before, and \emph{$\left[0,1\right]$} is called
\unknown~because it provides no information. Given a quantum
probability measure~$\mu:\events\rightarrow\left[0,1\right]$, we
define a quantum interval-valued probability
measure~$\bar{\mu}:\events\rightarrow\mathscr{I}$ by
$\bar{\mu}(P)=\iota\left(\mu(P)\right)$, where
$\iota:\left[0,1\right]\rightarrow\mathscr{I}$ is defined by
\[
\iota(x)=\begin{cases}
\necess & \textrm{if }x=1\textrm{ ;}\\
\imposs & \textrm{if }x=0\textrm{ ;}\\
\unknown & \textrm{otherwise.}
\end{cases}
\]
This measure represents the beliefs of an experimenter with no prior 
knowledge about the particular quantum system in question. Formally,
we can ask: what can we deduce about the state of a quantum system
given a quantum interval-valued probability measure, i.e., given
observations done with finite resources. In the case the intervals are
infinitely precise the question reduces to Gleason's theorem which
states that the state of the quantum system is uniquely determined by
the probability measure. But surely the less resources are available,
the less precise the intervals, and the less we expect to know about
the state of the system. To formally state and answer this question we
begin with defining the \emph{core} and \emph{convexity} of a
probability measure as follows.

\begin{definition}
  Given a quantum interval-valued probability
  measure~$\bar{\mu}:\events\rightarrow\mathscr{I}$:
\begin{itemize}
\item A \emph{core} of $\bar{\mu}$ is the set
  $\mathrm{core}\left(\bar{\mu}\right)=\left\{
    \pmeas:\events\rightarrow[0,1] ~\middle|~ \forall
    E\in\events.~\pmeas\left(E\right)\in\bar{\mu}\left(E\right)\right\}$.
\item $\bar{\mu}$ is called convex if
  $\bar{\mu}\left(P_{0}\vee
    P_{1}\right)+\bar{\mu}\left(P_{0}P_{1}\right)\subseteq\bar{\mu}\left(P_{0}\right)+\bar{\mu}\left(P_{1}\right)$
  for all commuting $P_{0},P_{1}\in\events$.
\end{itemize}
\end{definition}

\noindent The core of an interval-valued probability measure is the
set of real-valued infinitely-precise probability measures it
approximates. An interval-valued probability measure is convex if
whenever certain intervals exist then combinations of these intervals
must also exist, guaranteeing we can add and manipulate probabilities
coherently. In the classical world, every convex measure has a
non-empty core, which means that the interval-valued probability
measure must approximate at least one infinitely-precise measure.

\begin{thm}[Shapley~\cite{Shapley1971,,Grabisch2016}]\label{thm:Shapley}
  Every (classical) convex interval-valued probability measure has a
  non-empty core.
\end{thm}

In informal terms, this result states that although measurements done
with limited resources and poor precision may not uniquely identify
the true state of the system, there is always at least one system that
is consistent with the measurements. Surprisingly, we discovered a
counterexample to this statement in the quantum case, i.e., we
constructed the following convex quantum interval-valued probability
measure with an empty core.

\begin{example}[Three-dimensional quantum three-interval-valued 
  probability measure]\label{ex:three-dimensional-three-value} Given
  a three dimensional Hilbert space with an orthonormal basis
  $\left\{ \ket{0},\ket{1},\ket{2}\right\} $.  Let \emph{
    $\mathscr{I}=\left\{ \necess,\imposs,\unknown\right\} $},
  $\ket{\ps}=\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$,
  $\ket{\ps'}=\frac{1}{\sqrt{2}}(\ket{0}+\ket{2})$, and
\begin{eqnarray*}
\bar{\mu}(\mathbb{0})=\bar{\mu}(\proj{0})=\bar{\mu}(\proj{\ps})=\bar{\mu}(\proj{\ps'})
  &=& \imposs\\
\bar{\mu}(\mathbb{1})=\bar{\mu}(\mathbb{1}-\proj{0})=\bar{\mu}(\mathbb{1}-\proj{\ps})=\bar{\mu}(\mathbb{1}-\proj{\ps'})
  &=& \necess \\
\bar{\mu}(P) 
  &=& \unknown\quad\textrm{otherwise}
\end{eqnarray*}
It is straightforward to verify that $\bar{\mu}$ is a convex quantum
interval-valued probability measure. Now assume there exists a
real-valued quantum probability measure $\mu$ such that
$\mu(P)\in\bar{\mu}(P)$ for every event (projection)~$P$. We derive a
contradiction as follows. Suppose $\mu(P)\in\bar{\mu}(P)$ then we must
have $\mu(\proj{0})=\mu(\proj{\ps})=\mu(\proj{\ps'})=0$. By Gleason's
theorem, there is a mixed
state~$\rho=\sum_{j=1}^{N}q_{j}\proj{\phi_{j}}$ such that
$\mu\left(P\right)=\sum_{j=1}^{N}q_{j}\ip{\phi_{j}}{P\phi_{j}}$, where
$\sum_{j=1}^{N}q_{j}=1$ and $q_{j}>0$.  However, no pure
state~$\ket{\phi}$ can satisfy
$\ip{\phi}{0}=\ip{\phi}{\ps}=\ip{\phi}{\ps'}=0$; a contradiction.
\end{example}

\begin{figure}
\begin{center}
\includegraphics[scale=0.38]{proposal/measure4.pdf}
\end{center}
\caption{\label{fig:three-dimensional-4-value}This figure illustrates
  cases 1 and 2 of example~\ref{ex:three-dimensional-4-value} plotted
  in $\mathbb{R}^{3}$. The red and green dotted vectors are $\ket{0}$
  and $\ket{\ps}$ respectively.  All possible real vectors of the subspaces
  $\ket{0_{\theta,\gamma}^{\perp}}$ and
  $\ket{\ps_{\theta,\gamma}^{\perp}}$ are drawn in the red and green
  circles, respectively. Within the circles, a dotted
  vector~$\ket{\psi}$ means $\bar{\mu}(\proj{\psi})=\likely$;
  otherwise, $\bar{\mu}(\proj{\psi})=\unlikely$. The gray vector is a
  generic vector~$\ket{0_{\theta,\gamma}^{\perp}}$, and the red and
  green solid vectors are normalized
  $\ket{0}\times\ket{0_{\theta,\gamma}^{\perp}}$ and
  $\ket{\ps}\times\ket{0_{\theta,\gamma}^{\perp}}$, respectively, where
  $\times$ is the usual cross product in $\mathbb{R}^{3}$.}
\end{figure}

Looking closely at the example above, we might think that the
probability measure $\bar{\mu}$ is induced by the state $\ket{2}$
because $\bar{\mu}(\proj{0})=\bar{\mu}(\proj{\ps})=\imposs$, or we
might think it is induced by the state $\ket{1}$ because
$\bar{\mu}(\proj{0})=\bar{\mu}(\proj{\ps'})=\imposs$, or yet we might
think it is induced by the mixed state $\frac{\mathbb{1}}{3}$ because
$\bar{\mu}(\proj{\phi})\ne\necess$ for all $\ket{\phi}$. Each of these
possibilities is compatible with some but not all of the
observations. All is not lost however: if the observations are made
more precise, we conjecture that some of the inconsistencies
disappear. A partial proof of this conjecture is the following example
which refines the previous probability measure by adding more precise
intervals. It remains to prove that this refined measure is convex,
however. 

\begin{example}[Three-dimensional quantum four-interval-valued 
  probability measure]\label{ex:three-dimensional-4-value}
  Given a three dimensional Hilbert space with an orthonormal basis
  $\left\{ \ket{0},\ket{1},\ket{2}\right\} $.  Let \emph{
  }$\mathscr{I}=\left\{ \imposs,\unlikely,\likely,\necess\right\} $,
  $\ket{\ps}=\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$, and
  $\ket{\ms}=\frac{1}{\sqrt{2}}(\ket{0}-\ket{1})$. The definition of
  $\bar{\mu}$ below refers to Fig.~\ref{fig:three-dimensional-4-value}
  which plots the 1-dimensional projectors:
\begin{enumerate}
\item Let:
\begin{eqnarray*}
\bar{\mu}(\mathbb{0})=\bar{\mu}(\proj{0})=\bar{\mu}(\proj{\ps}) 
  &=& \imposs \\
\bar{\mu}(\mathbb{1})=\bar{\mu}(\mathbb{1}-\proj{0})=\bar{\mu}(\mathbb{1}-\proj{\ps}) 
  &=& \necess
\end{eqnarray*}
where $\ket{0}$ and $\ket{\ps}$ are plotted as the red and green dotted
vectors, respectively.
\item The red and green circles are are the states orthogonal to
  $\ket{0}$ and $\ket{\ps}$, respectively, and can be parametrized as
  $\ket{0_{\theta,\gamma}^{\perp}}=\rme^{\rmi\gamma}\sin\theta\ket{1}+\cos\theta\ket{2}$
  and
  $\ket{\ps_{\theta,\gamma}^{\perp}}=-\rme^{\rmi\gamma}\sin\theta\ket{\ms}+\cos\theta\ket{2}$,
  where $0\le\theta\le\frac{\pi}{2}$ and $0\le\gamma<2\pi$. The dotted
  half of those states need special treatment, i.e., whenever
  $0\le\theta<\frac{\pi}{2}$ and $0\le\gamma<\pi$, we define
\begin{eqnarray*}
\bar{\mu}\left(\proj{0_{\theta,\gamma}^{\perp}}\right)=\bar{\mu}\left(\proj{\ps_{\theta,\gamma}^{\perp}}\right)
  &=& \likely \\
\bar{\mu}\left(\mathbb{1}-\proj{0_{\theta,\gamma}^{\perp}}\right)=
  \bar{\mu}\left(\mathbb{1}-\proj{\ps_{\theta,\gamma}^{\perp}}\right) 
  &=& \unlikely
\end{eqnarray*}
\item Otherwise, $\bar{\mu}(\proj{\psi})=\unlikely$ and $\bar{\mu}(\mathbb{1}-\proj{\psi})=\likely$. 
\end{enumerate}
It is straightforward but tedious to check that $\bar{\mu}$ is a
quantum interval-valued probability measure. Although we have not
verified that $\bar{\mu}$ is convex, the following argument
establishes that is has an empty core. Assume there is a real-valued
probability measure satisfying $\mu_{\rho}^{B}(P)\in\bar{\mu}(P)$ for
all $P\in\events$. Because
$\mu_{\rho}^{B}(\proj{0})\in\bar{\mu}(\proj{0})=\imposs$ and
$\mu_{\rho}^{B}(\proj{\ps})\in\bar{\mu}(\proj{\ps})=\imposs$, we must
have $\mu_{\rho}^{B}(\proj{0})=\mu_{\rho}^{B}(\proj{\ps})=0$ so that
$\mu_{\rho}^{B}=\mu_{\ket{2}}^{B}$. However,
\[
\mu_{\ket{2}}^{B}(\proj{2})=1\notin\unlikely=\bar{\mu}(\proj{2})\textrm{ .}
\]
This measure however is ``better'' than the previous one in the sense
that it might only be induced by $\ket{2}$ or the density matrix
$\frac{\mathbb{1}}{3}$, but not by
$\ket{1}$. 
\end{example}

In general, we conjecture that if the measurement equipment is made
more and more precise, the corresponding interval-valued probability
measure will be closer and closer to the Born rule. In the limit case,
$\mathscr{I}=\left\{ \left\{ a\right\}
  ~\middle|~a\in\left[0,1\right]\right\}$
we do indeed recover the conventional Gleason's theorem and the Born
rule.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion and Discussion}

If we insist that probabilities cannot be computed to infinite precision
and are bound to be approximations represented by intervals of confidence,
then quantum states themselves can only be discussed within intervals
of confidence. Despite the fact that classically a interval-valued
probability measure could always correspond to a real-valued probability
measure, we found that there may be no ``real'' infinitely-precise
quantum state approximated by a quantum interval-valued probability
measure as a whole. However, if a quantum interval-valued probability
measure is decomposed into pieces, each piece might still be induced
by a quantum state. Moreover, our examples and Gleason's theorem summarized
in table~\ref{table_long} suggests that as the measurement resources
increase, an entire quantum interval-valued probability measure could
more and more likely be identified to a particular state. 
\begin{table}[ht]
\center{%
\begin{tabular}{c|cccc}
Measurement resources & Lowest & \multicolumn{2}{c}{$\longleftrightarrow$} & Highest\tabularnewline
\hline 
Count of $\mathscr{I}$ & $3$ & $4$ & \ldots{} & $\infty$\tabularnewline
$\sup_{\left[l,r\right]\in\mathscr{I}}\left|r-l\right|$ & $1$ & $\frac{1}{2}$ & \ldots{} & $0$\tabularnewline
Count of $\mathrm{core}\left(\bar{\mu}\right)$ & 0 & 0 &  & 1\tabularnewline
Count of states might correspond to $\bar{\mu}$ & $3$ & $2$ & \ldots{} & $1$\tabularnewline
\hline 
How precise we could identify a state? & Coarse & \multicolumn{2}{c}{$\longleftrightarrow$} & Precise\tabularnewline
\end{tabular}}\caption{Relation between measurement resources and interval-valued probability
measures}
\label{table_long}
\end{table}
Additional work is in progress on the following research questions:
\begin{description}
\item [{Research Question.}] Confirm that there is always a quantum interval-valued
probability measure with an empty-core if the length of the intervals
is bigger than zero. 
\item [{Research Question.}] Find a general method to determine how a
quantum interval-valued probability measure is close to the Born rule. 
\item [{Research Question.}] Confirm that as the number and precision
of the intervals increase the quantum interval-valued probability
measure converges to the measure induced by the Born rule. 
\item [{Research Question.}] Investigate the status of the theorems of
Gleason, Bell~\cite{BellBook1987,Redhead1987-REDINA,peres1995quantum,Jaeger2007}
and Kochen-Specker for quantum interval-valued probability measures.
\end{description}
Although we discussed how a quantum interval-valued probability measure
could be induced from a real quantum state, our investigation leaves
an open question of whether there exists a ``real'' entity that
exists independently of measurements and probabilities. The possibility
of no ``real'' underlying state is consistent with the elegantly
recent work on Quantum Bayesianism or QBism~\cite{Fuchs2010,VonBaeyer2016,Fuchs2012},
which suggests that the quantum state is more like an interactive
system in computer science parlance. In another word, the quantum
state is subjective: each observer has a different view of the quantum
system that is consistent with their previous observations and that
allows that observer, independently of other observers, to assign
beliefs (i.e., probabilities) to possible future interactions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage{}%
\begin{comment}
 \bibliographystyle{plain}
\bibliography{proposal/prop}
 
\end{comment}
\printbibliography 
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



